# ===================================================================
# TEMPLATE PADRONIZADO CSPBench - ESTRUTURA UNIFICADA v0.2
# ===================================================================
# Este template define a estrutura padrão para todos os tipos de batch.
# Tipos suportados: execution, optimization, sensitivity
# Uso: Copie este template e adapte para sua necessidade específica

# =====================================================================
# SEÇÃO 1: METADADOS (OBRIGATÓRIO PARA TODOS)
# =====================================================================
# Esta seção contém informações básicas sobre o batch.
# Todos os campos são obrigatórios para rastreabilidade e documentação.
metadados:
  nome: "Nome do Batch"                    # Nome descritivo do batch (string)
  descricao: "Descrição detalhada do que o batch faz"  # Descrição completa (string)
  autor: "Nome do Autor"                   # Autor responsável (string)
  versao: "1.0"                           # Versão do batch (string)
  data_criacao: "2025-07-13"              # Data de criação no formato YYYY-MM-DD
  tags: ["tag1", "tag2"]                  # Tags para categorização (list)
  timeout_global: 3600                    # Timeout global em segundos (int)
                                          # Valores comuns: 3600 (1h), 7200 (2h), 14400 (4h)

# =====================================================================
# SEÇÃO 2: CONFIGURAÇÕES DE INFRAESTRUTURA (OPCIONAL)
# =====================================================================
# Esta seção permite sobrepor configurações do arquivo settings.yaml.
# Use apenas se precisar de configurações específicas para este batch.
infrastructure:
  # Sistema de histórico - controla como o histórico de execução é salvo
  history:
    save_history: true                   # bool: Salvar histórico detalhado
                                        # true = salva cada iteração, false = apenas resultado final
    plot_history: true                  # bool: Gerar gráficos do histórico
                                       # true = cria plots de convergência, false = sem plots
    history_frequency: 1               # int: Frequência de salvamento (a cada N iterações)
                                      # 1 = cada iteração, 10 = a cada 10 iterações
    history_plots:
      plot_convergence: true           # bool: Gráfico de convergência do algoritmo
      plot_fitness_evolution: true     # bool: Evolução do fitness ao longo do tempo
      plot_best_solutions: true        # bool: Timeline das melhores soluções encontradas
      plot_parameters: true            # bool: Evolução de parâmetros adaptativos
      plot_format: "png"               # string: Formato dos plots ("png"|"pdf"|"svg")
  
  # Sistema de resultados - controla como os resultados são persistidos
  result:
    save_partial_results: true         # bool: Salvar resultados parciais durante execução
                                      # true = salva incrementalmente, false = apenas no final
    partial_file: "partial_results.json" # string: Nome do arquivo de resultados parciais 

# =====================================================================
# SEÇÃO 3: DATASETS (PADRONIZADO PARA TODOS)
# =====================================================================
# Define os datasets disponíveis para uso no batch.
# Cada dataset tem um ID único que pode ser referenciado nas execuções.
# Tipos suportados: synthetic, file, entrez
datasets:
  # === DATASETS SINTÉTICOS ===
  # Geram dados artificiais para testes e desenvolvimento
  - id: dataset_teste                    # string: ID único do dataset
    nome: "Dataset de Teste"             # string: Nome descritivo
    tipo: "synthetic"                    # string: Tipo do dataset
    parametros:                          # Parâmetros específicos para datasets sintéticos:
      n: 10                             # int: Número de sequências (3-100 recomendado)
      L: 20                             # int: Comprimento das sequências (5-1000)
      alphabet: "ACGT"                  # string: Alfabeto das sequências
                                       # "ACGT" = DNA, "01" = binário, "ACDEFGH..." = personalizado
      noise: 0.1                       # float: Nível de ruído (0.0-1.0)
                                       # 0.0 = sem ruído, 0.5 = muito ruído
      fully_random: false              # bool: Sequências completamente aleatórias
                                       # false = baseadas em padrões, true = aleatórias
      seed: 42                         # int|null: Semente para reprodutibilidade
                                      # int = determinístico, null = aleatório

  # === DATASETS DE ARQUIVO ===
  # Carregam dados de arquivos FASTA existentes
  - id: dataset_arquivo                 # string: ID único do dataset
    nome: "Dataset de Arquivo"          # string: Nome descritivo
    tipo: "file"                        # string: Tipo do dataset
    parametros:                         # Parâmetros específicos para datasets de arquivo:
      filename: "exemplo.fasta"         # string: Nome do arquivo (deve estar em datasets/)
                                       # Formatos suportados: .fasta, .fa, .txt

  # === DATASETS ENTREZ (NCBI) ===
  # Baixam dados diretamente do NCBI usando a API Entrez
  - id: dataset_ncbi                    # string: ID único do dataset
    nome: "Dataset NCBI"                # string: Nome descritivo
    tipo: "entrez"                      # string: Tipo do dataset
    parametros:                         # Parâmetros específicos para datasets Entrez:
      query: "COIGene AND 600:650[SLEN]" # string: Query de busca no NCBI
                                         # Sintaxe: https://www.ncbi.nlm.nih.gov/books/NBK25499/
      db: "nucleotide"                   # string: Banco de dados NCBI
                                        # "nucleotide", "protein", "pubmed", etc.
      retmax: 10                        # int: Número máximo de sequências a baixar (1-10000)
                                       # ATENÇÃO: Valores altos podem ser lentos

# =====================================================================
# SEÇÃO 4: ALGORITMOS (PADRONIZADO PARA TODOS)
# =====================================================================
# Define configurações de algoritmos que podem ser reutilizadas.
# Permite criar "presets" de parâmetros para diferentes cenários.
algorithms:
  - id: "config_padrao"                 # string: ID único da configuração
    nome: "Configuração Padrão"         # string: Nome descritivo
    descricao: "Algoritmos com parâmetros padrão"  # string: Descrição detalhada
    algorithms:                         # list: Lista de algoritmos incluídos nesta configuração
      - "Baseline"                      # Algoritmo de linha de base (mais simples)
      - "BLF-GA"                        # Block-based Genetic Algorithm (principal)
      - "CSC"                           # Closest String with Constraints
      - "H³-CSP"                        # Heuristic Closest String Problem
      - "DP-CSP"                        # Dynamic Programming CSP
    
    # Parâmetros específicos por algoritmo
    # Para execution: valores fixos usados diretamente
    # Para optimization/sensitivity: valores base que podem ser sobrescritos
    algorithm_params:
      # === BASELINE - Algoritmo Guloso Simples ===
      "Baseline":
        tie_break: "lex"                # string: Critério de desempate
                                       # "lex" = lexicográfico, "random" = aleatório, "first" = primeiro
      
      # === BLF-GA - Block-based Genetic Algorithm ===
      "BLF-GA":
        # Parâmetros de População
        pop_size: 100                   # int: Tamanho da população (50-500 recomendado)
        max_gens: 200                   # int: Número máximo de gerações (100-1000)
        
        # Operadores Genéticos
        cross_prob: 0.8                 # float: Probabilidade de crossover (0.6-0.95)
        mut_prob: 0.1                   # float: Probabilidade de mutação (0.01-0.3)
        elite_rate: 0.05                # float: Taxa de elitismo (0.01-0.15)
        
        # Parâmetros de Blocos (específicos do BLF-GA)
        initial_blocks: 0.2             # float: Proporção inicial de blocos (0.1-0.5)
        rediv_freq: 10                  # int: Frequência de redivisão (5-25)
        
        # Diversidade e Imigração
        immigrant_freq: 15              # int: Frequência de imigração (10-30)
        immigrant_ratio: 0.2            # float: Taxa de imigração (0.1-0.3)
        
        # Tipos de Operadores
        crossover_type: "one_point"     # string: Tipo de crossover
                                       # "one_point", "uniform", "blend_blocks"
        mutation_type: "multi"          # string: Tipo de mutação
                                       # "multi", "inversion", "transposition"
        selection_type: "tournament"    # string: Tipo de seleção
                                       # "tournament", "roulette", "ranking"
        refinement_type: "greedy"       # string: Tipo de refinamento local
                                       # "greedy", "swap", "insertion", "2opt"
        
        # Critérios de Parada
        no_improve_patience: 0.3        # float: Paciência sem melhoria (0.1-0.5)
                                       # Proporção de gerações sem melhoria antes de parar
      
      # === CSC - Closest String with Constraints ===
      "CSC":
        min_d: 2                        # int: Distância mínima inicial (1-5)
        d_factor: 0.75                  # float: Fator de incremento da distância (0.5-1.0)
        min_blocks: 4                   # int: Número mínimo de blocos (2-8)
        max_blocks: 8                   # int: Número máximo de blocos (4-16)
        l_div: 25                       # int: Divisor para comprimento de blocos (10-50)
      
      # === H³-CSP - Heuristic Closest String Problem ===
      "H³-CSP":
        auto_blocks: true               # bool: Divisão automática de blocos
                                       # true = automática, false = manual
        min_block_size: 2               # int: Tamanho mínimo de bloco (1-5)
        block_size: 4                   # int: Tamanho padrão de bloco (2-8)
        k_candidates: 5                 # int: Número de candidatos considerados (3-10)
        local_iters: 3                  # int: Iterações de busca local (1-5)
        fallback_enabled: true          # bool: Habilitar fallback para blocos grandes
      
      # === DP-CSP - Dynamic Programming CSP ===
      "DP-CSP":
        max_d: 5                        # int: Distância máxima considerada (3-10)
                                       # Valores altos aumentam muito o tempo de execução
        warn_threshold: 50              # int: Limite de sequências para aviso (20-100)
                                       # Acima deste valor, o algoritmo pode ser muito lento
        seed: null                      # int|null: Semente para reprodutibilidade

# =====================================================================
# SEÇÃO 5: TIPO DE TAREFA (OBRIGATÓRIO)
# =====================================================================
# Define o tipo de operação que será realizada.
# Cada tipo tem configurações específicas na seção correspondente.
task:
  type: "execution"                     # string: Tipo da tarefa
                                       # "execution" = executar algoritmos com parâmetros fixos
                                       # "optimization" = otimizar hiperparâmetros com Optuna
                                       # "sensitivity" = analisar sensibilidade com SALib

# =====================================================================
# SEÇÃO 6A: CONFIGURAÇÃO ESPECÍFICA - EXECUTION
# =====================================================================
# Use esta seção quando task.type = "execution"
# Executa algoritmos em datasets com parâmetros pré-definidos
execution:
  # Lista de execuções a realizar
  executions:
    - nome: "Execução Teste"            # string: Nome descritivo da execução
      datasets: ["dataset_teste"]       # list: IDs dos datasets a usar (referência à seção 3)
      algorithms: ["config_padrao"]     # list: IDs das configurações de algoritmos (referência à seção 4)
      repetitions: 1                   # int: Número de repetições por combinação (1-10 recomendado)
                                       # Cada combinação dataset+algoritmo será executada N vezes
    # Você pode adicionar múltiplas execuções:
    # - nome: "Execução Completa"
    #   datasets: ["dataset_teste", "dataset_arquivo"]
    #   algorithms: ["config_padrao"]
    #   repetitions: 5

# =====================================================================
# SEÇÃO 6B: CONFIGURAÇÃO ESPECÍFICA - OPTIMIZATION
# =====================================================================
# Use esta seção quando task.type = "optimization"
# Otimiza hiperparâmetros de algoritmos usando Optuna
optimization:
  # Framework de otimização (configuração global)
  method: "optuna"                      # string: Framework de otimização (apenas "optuna" suportado)
  
  # Configurações globais do Optuna (aplicadas a todas as otimizações)
  global_optuna_config:
    sampler: "TPESampler"              # string: Algoritmo de amostragem padrão
                                      # "TPESampler" = Tree-structured Parzen Estimator (recomendado)
                                      # "RandomSampler" = Amostragem aleatória
                                      # "CmaEsSampler" = CMA-ES para problemas contínuos
    pruner: "MedianPruner"             # string: Algoritmo de poda padrão
                                      # "MedianPruner" = para com base na mediana
                                      # "SuccessiveHalvingPruner" = halving sucessivo
    n_startup_trials: 10               # int: Trials antes de usar sampler inteligente
    n_warmup_steps: 10                 # int: Steps de warmup para o pruner
    interval_steps: 5                  # int: Intervalo para avaliação do pruner
    multivariate: true                 # bool: Usar TPE multivariado (recomendado)
    n_ei_candidates: 24                # int: Candidatos para Expected Improvement
    storage: null                      # string|null: URL do banco de dados (null = em memória)
  
  # Lista de otimizações a realizar
  optimizations:
    - nome: "Otimização BLF-GA"        # string: Nome descritivo da otimização
      study_name: "estudo_blfga"       # string: Nome do estudo para identificação
      direction: "minimize"             # string: Direção da otimização
                                       # "minimize" = minimizar objetivo (para distância)
                                       # "maximize" = maximizar objetivo (para qualidade)
      n_trials: 100                    # int: Número de trials/tentativas (50-1000 recomendado)
      timeout_per_trial: 300           # int: Timeout por trial em segundos (60-600)
      
      # Datasets e algoritmo específicos para otimizar
      target_datasets: ["dataset_teste"] # list: IDs dos datasets a usar (referência à seção 3)
      target_algorithm: "BLF-GA"       # string: Nome do algoritmo a otimizar
      
      # Parâmetros a otimizar (sobrepõem algorithm_params da seção 4)
      # Tipos suportados: int, uniform (float), categorical
      parameters:
        pop_size:                      # Nome do parâmetro (deve existir no algoritmo)
          type: "int"                  # string: Tipo do parâmetro
          low: 50                      # int: Valor mínimo (para int/uniform)
          high: 200                    # int: Valor máximo (para int/uniform)
          step: 10                     # int: Passo para valores inteiros (opcional)
        
        max_gens:
          type: "int"
          low: 100
          high: 500
          step: 25
        
        cross_prob:
          type: "uniform"              # float uniforme entre low e high
          low: 0.6
          high: 0.95
        
        mut_prob:
          type: "uniform"
          low: 0.01
          high: 0.3
        
        crossover_type:
          type: "categorical"          # Escolha entre valores discretos
          choices: ["one_point", "uniform", "blend_blocks"]  # list: Opções disponíveis
      
      # Configurações específicas do Optuna (opcional - sobrepõe global_optuna_config)
      optuna_config:
        sampler: "TPESampler"          # string: Algoritmo de amostragem específico
        pruner: "MedianPruner"         # string: Algoritmo de poda específico
        storage: null                  # string|null: URL do banco específico
    
    # Exemplo de segunda otimização (você pode adicionar quantas precisar)
    # - nome: "Otimização CSC"
    #   study_name: "estudo_csc"
    #   direction: "minimize"
    #   n_trials: 50
    #   timeout_per_trial: 180
    #   target_datasets: ["dataset_teste", "dataset_arquivo"]
    #   target_algorithm: "CSC"
    #   parameters:
    #     min_d:
    #       type: "int"
    #       low: 1
    #       high: 5
    #     d_factor:
    #       type: "uniform"
    #       low: 0.5
    #       high: 1.0

# =====================================================================
# SEÇÃO 6C: CONFIGURAÇÃO ESPECÍFICA - SENSITIVITY
# =====================================================================
# Use esta seção quando task.type = "sensitivity"
# Realiza análises de sensibilidade dos parâmetros usando SALib
sensitivity:
  # Framework de análise (configuração global)
  method: "SALib"                       # string: Framework de análise (apenas "SALib" suportado)
  
  # Configurações globais do SALib (aplicadas a todas as análises)
  global_salib_config:
    n_samples: 1000                    # int: Número de amostras padrão para gerar (100-10000)
                                      # Mais amostras = maior precisão mas mais tempo
    repetitions_per_sample: 3          # int: Repetições por amostra padrão (1-10)
                                      # Para reduzir ruído nos resultados
    seed: 42                          # int: Seed global para reprodutibilidade
    parallel: true                    # bool: Usar processamento paralelo
  
  # Lista de análises de sensibilidade a realizar
  analyses:
    - nome: "Análise Morris BLF-GA"    # string: Nome descritivo da análise
      analysis_method: "morris"         # string: Método de análise de sensibilidade
                                      # "morris" = Análise de Morris (elementary effects) - recomendado para screening
                                      # "sobol" = Análise de Sobol (índices de primeira ordem e total)
                                      # "fast" = Análise FAST (Fourier Amplitude Sensitivity)
                                      # "delta" = Delta method
      
      # Datasets e algoritmo específicos para analisar
      target_datasets: ["dataset_teste"] # list: IDs dos datasets a usar (referência à seção 3)
      target_algorithm: "BLF-GA"       # string: Nome do algoritmo a analisar
      
      # Configurações específicas da análise (opcional - sobrepõe global_salib_config)
      n_samples: 1000                  # int: Número de amostras específico
      repetitions_per_sample: 3        # int: Repetições por amostra específico
      
      # Parâmetros a analisar (define os ranges de variação)
      parameters:
        pop_size:                      # Nome do parâmetro
          type: "integer"              # string: Tipo do parâmetro
          bounds: [50, 200]            # list: [min, max] para int/float
          default: 100                 # valor padrão para referência
          
        max_gens:
          type: "integer"
          bounds: [100, 500]
          default: 200
          
        cross_prob:
          type: "float"                # float contínuo
          bounds: [0.6, 0.95]
          default: 0.8
          
        mut_prob:
          type: "float"
          bounds: [0.01, 0.3]
          default: 0.1
          
        crossover_type:
          type: "categorical"          # Valores discretos
          values: ["one_point", "uniform", "blend_blocks"]  # list: Opções a variar
          default: "one_point"
      
      # Configuração específica do método Morris (se analysis_method = "morris")
      morris:
        num_levels: 4                  # int: Níveis para grade Morris (4-10)
        grid_jump: 2                   # int: Tamanho do salto na grade
        num_trajectories: 20           # int: Número de trajetórias a gerar
        optimal_trajectories: null     # int|null: Otimizar trajetórias (null = não otimizar)
      
      # Configuração específica do método Sobol (se analysis_method = "sobol")
      sobol:
        calc_second_order: true        # bool: Calcular índices de segunda ordem
        num_resamples: 1000           # int: Resamples para bootstrap de confiança
        conf_level: 0.95              # float: Nível de confiança (0.90-0.99)
        seed: 42                      # int: Seed para reprodutibilidade
      
      # Configuração específica do método FAST (se analysis_method = "fast")
      fast:
        M: 4                          # int: Fator de frequência interferência
        interference: false           # bool: Considerar interferência de frequência
        
      # Métricas de saída a analisar
      output_metrics:                 # list: Métricas a calcular sensibilidade
        - "distance"                  # Distância máxima alcançada
        - "execution_time"            # Tempo de execução
        # Outras opções: "convergence_rate", "fitness_calls", "diversity"
    
    # Exemplo de segunda análise (você pode adicionar quantas precisar)
    # - nome: "Análise Sobol CSC"
    #   analysis_method: "sobol"
    #   target_datasets: ["dataset_teste", "dataset_arquivo"]
    #   target_algorithm: "CSC"
    #   n_samples: 2000
    #   repetitions_per_sample: 5
    #   parameters:
    #     min_d:
    #       type: "integer"
    #       bounds: [1, 5]
    #       default: 2
    #     d_factor:
    #       type: "float"
    #       bounds: [0.5, 1.0]
    #       default: 0.75
    #   sobol:
    #     calc_second_order: true
    #     num_resamples: 1000
    #     conf_level: 0.95
    #   output_metrics:
    #     - "distance"
    #     - "execution_time"
    #     - "convergence_rate"

# =====================================================================
# SEÇÃO 7: CONFIGURAÇÕES DE EXPORTAÇÃO (OBRIGATÓRIO)
# =====================================================================
# Define onde e como os resultados serão salvos
export:
  enabled: true                        # bool: Habilitar exportação de resultados
                                      # true = salvar resultados, false = apenas executar
  
  destination: "outputs/{session_folder}"  # string: Diretório base para salvar
                                      # {session_folder} = pasta da sessão atual (timestamp)
                                      # {task_type} = tipo da tarefa (execution/optimization/sensitivity)
                                      # {algorithm_name} = nome do algoritmo
                                      # {dataset_name} = nome do dataset
  
  # Formatos de saída a gerar
  formats:
    csv: true                          # bool: Exportar resultados em CSV
    json: true                         # bool: Exportar resultados em JSON
    parquet: false                     # bool: Exportar em formato Parquet (para grandes volumes)
    pickle: false                      # bool: Exportar em formato Pickle (Python nativo)
    
  # Configurações específicas por formato
  csv_config:
    separator: ","                     # string: Separador de campos (,;|)
    encoding: "utf-8"                  # string: Codificação de caracteres
    include_index: true                # bool: Incluir índice do DataFrame
    decimal: "."                       # string: Separador decimal
    
  json_config:
    indent: 2                          # int|null: Indentação (null = compacto)
    ensure_ascii: false                # bool: Garantir ASCII (false = permite UTF-8)
    
  # Estrutura de diretórios detalhada
  directory_structure:
    use_algorithm_subfolder: true      # bool: Criar subpasta por algoritmo
    use_dataset_subfolder: true        # bool: Criar subpasta por dataset
    use_timestamp_suffix: true         # bool: Adicionar timestamp aos nomes
    
  # Conteúdo específico a incluir na exportação
  include:                            # list: Tipos de conteúdo a incluir
    - "summary"                       # Resumo executivo dos resultados
    - "detailed_results"              # Resultados detalhados de cada execução
    - "plots"                         # Gráficos e visualizações
    - "logs"                          # Logs de execução
    # Outras opções: "raw_data", "parameters", "metadata"

# =====================================================================
# SEÇÃO 8: CONFIGURAÇÕES DE VISUALIZAÇÃO (OPCIONAL)
# =====================================================================
# Define quais gráficos gerar e suas configurações visuais
plots:
  enabled: true                       # bool: Habilitar geração de gráficos
  
  # Gráficos comuns a todos os tipos de tarefa
  plot_convergence: true              # bool: Gráfico de convergência
  plot_comparison: true               # bool: Comparação entre algoritmos/parâmetros
  plot_boxplots: true                 # bool: Box plots de distribuições
  plot_scatter: true                  # bool: Scatter plots de correlações
  plot_heatmap: true                  # bool: Heatmaps de parâmetros
  plot_runtime: true                  # bool: Análise de tempo de execução
  plot_success_rate: true             # bool: Taxa de sucesso/convergência
  
  # Gráficos específicos por tipo de tarefa
  # Para optimization:
  plot_optimization_history: true    # bool: Histórico de otimização Optuna
  plot_parameter_importance: true    # bool: Importância dos parâmetros
  plot_parallel_coordinate: true     # bool: Gráfico de coordenadas paralelas
  
  # Para sensitivity:
  plot_sensitivity_indices: true     # bool: Índices de sensibilidade
  plot_morris_trajectories: true     # bool: Trajetórias Morris
  plot_interaction_effects: true     # bool: Efeitos de interação
  
  # Configurações visuais gerais
  style: "seaborn-v0_8"              # string: Estilo do matplotlib
                                     # "seaborn-v0_8", "ggplot", "bmh", "classic"
  figure_size: [12, 8]               # list: Tamanho da figura [largura, altura] em polegadas
  dpi: 300                           # int: Resolução em DPI (150-300 recomendado)
  color_palette: "Set2"              # string: Paleta de cores
                                     # "Set1", "Set2", "tab10", "viridis", "plasma"
  
  # Configurações de formato de saída
  formats:                           # list: Formatos para salvar gráficos
    - "png"                          # Formato PNG (recomendado para web)
    - "pdf"                          # Formato PDF (recomendado para publicação)
    # - "svg"                        # Formato SVG (vetorial)
    # - "eps"                        # Formato EPS (para LaTeX)
  
  # Configurações avançadas
  font_size: 12                      # int: Tamanho da fonte padrão
  title_size: 16                     # int: Tamanho do título
  label_size: 14                     # int: Tamanho dos labels dos eixos
  legend_size: 10                    # int: Tamanho da legenda
  tight_layout: true                 # bool: Usar layout apertado automaticamente

# =====================================================================
# SEÇÃO 9: CONFIGURAÇÕES DE MONITORAMENTO (OPCIONAL)
# =====================================================================
# Configurações para monitoramento em tempo real da execução
monitoring:
  # Monitoramento geral
  enabled: true                      # bool: Habilitar monitoramento
  interface: "simple"                # string: Tipo de interface
                                    # "simple" = interface simples no terminal (padrão)
                                    # "tui" = interface avançada com curses
  update_interval: 3                 # int: Intervalo de atualização em segundos (1-10)
  
 
# =====================================================================
# SEÇÃO 10: CONFIGURAÇÕES DE RECURSOS (OPCIONAL)
# =====================================================================
# Controle de uso de recursos computacionais
resources:
  # Limitações de CPU
  cpu:
    max_cores: null                  # int|null: Máximo de cores a usar (null = todos)
    affinity: null                   # list|null: Cores específicos para usar [0,1,2,3]
    
  # Limitações de memória
  memory:
    max_memory_gb: null              # float|null: Máximo de memória em GB
    
  # Processamento paralelo
  parallel:
    enabled: true                    # bool: Habilitar paralelização quando possível
    max_workers: null                # int|null: Máximo de workers paralelos (null = auto)
    internal_jobs: 4                 # int: Número máximo de jobs paralelos internos por algoritmo
                                    # Controla paralelismo interno do algoritmo (threads/processos)
                                    # Valor sugerido: 4 para CPUs com 8+ cores
                                    # Relação: max_workers × internal_jobs ≤ CPU_cores
    backend: "threading"             # string: Backend de paralelização
                                    # "threading" = threads (I/O bound)
                                    # "multiprocessing" = processos (CPU bound)
    chunk_size: null                # int|null: Tamanho dos chunks para divisão
    
  # Timeouts e limites
  timeouts:
    per_algorithm_run: 3600          # int: Timeout por execução de algoritmo (segundos)
    total_batch: 86400               # int: Timeout total do batch (segundos)
    
  # Configurações de GPU (se disponível)
  gpu:
    enabled: false                   # bool: Usar GPU se disponível
    device_id: 0                     # int: ID do dispositivo GPU a usar

# =====================================================================
# SEÇÃO 11: CONFIGURAÇÕES DE LOGGING (OPCIONAL)
# =====================================================================
# Controle detalhado dos logs de execução
logging:
  # Nível geral de logging
  level: "INFO"                      # string: Nível de log
                                    # "DEBUG" = logs muito detalhados
                                    # "INFO" = logs informativos (recomendado)
                                    # "WARNING" = apenas avisos e erros
                                    # "ERROR" = apenas erros
  
  # Configurações de saída dos logs
  output:
    console: true                    # bool: Exibir logs no console
    file: true                       # bool: Salvar logs em arquivo
    
  # Configurações do arquivo de log
  file_config:
    filename: "execution.log"        # string: Nome do arquivo de log
    max_size_mb: 100                # int: Tamanho máximo do arquivo em MB
    backup_count: 5                  # int: Número de backups rotativos
    encoding: "utf-8"               # string: Codificação do arquivo
    
  # Formatação das mensagens
  format:
    timestamp_format: "%Y-%m-%d %H:%M:%S"  # string: Formato do timestamp
    message_format: "[{timestamp}] {level} - {message}"  # string: Formato da mensagem
    
  # Logs específicos por componente
  components:
    algorithms: "INFO"               # string: Nível para logs de algoritmos
    infrastructure: "WARNING"       # string: Nível para logs de infraestrutura
    optimization: "INFO"             # string: Nível para logs de otimização
    sensitivity: "INFO"              # string: Nível para logs de análise de sensibilidade
    
  # Configurações avançadas
  filters:
    exclude_patterns: []             # list: Padrões de mensagens a excluir
    include_only: []                 # list: Apenas incluir mensagens com estes padrões
    
  # Logs estruturados (para análise posterior)
  structured:
    enabled: false                   # bool: Habilitar logs estruturados em JSON
    include_context: true            # bool: Incluir contexto extra (parâmetros, etc.)

# =====================================================================
# SEÇÃO 12: CONFIGURAÇÕES DE SISTEMA (OPCIONAL)
# =====================================================================
# Configurações gerais do sistema e comportamento
system:
  # Controle de reprodutibilidade
  reproducibility:
    global_seed: 42                  # int: Seed global para reprodutibilidade
    strict_mode: true                # bool: Modo estrito (garante mesmo resultado)
    
  # Configurações de checkpoint e recuperação
  checkpointing:
    enabled: true                    # bool: Habilitar salvamento de progresso
    interval: 5                      # int: Intervalo para checkpoint (minutos)
    recovery: true                   # bool: Tentar recuperar de checkpoint anterior
    max_checkpoints: 3               # int: Máximo de checkpoints a manter
    
  # Controle de progresso
  progress:
    show_progress_bar: true          # bool: Exibir barra de progresso
    log_interval: 5                  # int: Intervalo para log de progresso (segundos)
    update_interval: 30              # int: Intervalo para atualização de status (segundos)
    
  # Parada antecipada (para otimização)
  early_stopping:
    enabled: false                   # bool: Habilitar parada antecipada
    patience: 20                     # int: Número de trials sem melhoria
    min_improvement: 0.001           # float: Melhoria mínima considerada significativa
    
  # Configurações de erro e tratamento
  error_handling:
    continue_on_error: false         # bool: Continuar execução mesmo com erros
    max_retries: 3                   # int: Máximo de tentativas em caso de erro
    retry_delay: 5                   # int: Delay entre tentativas (segundos)
    
  # Limpeza automática
  cleanup:
    temp_files: true                 # bool: Limpar arquivos temporários
    old_logs: true                   # bool: Limpar logs antigos
    old_results: false               # bool: Limpar resultados antigos
    retention_days: 30               # int: Dias para manter arquivos antigos

# =====================================================================
# FIM DO TEMPLATE PADRONIZADO
# =====================================================================
# Para usar este template:
# 1. Copie este arquivo e renomeie para sua configuração específica
# 2. Modifique apenas as seções relevantes para seu caso de uso
# 3. Remova as seções não utilizadas (todas as seções opcionais)
# 4. Execute: python main.py seu_arquivo.yaml
# 
# Exemplos prontos disponíveis:
# - processamento_padrao.yaml (execução simples)
# - otimizacao_padrao.yaml (otimização com Optuna)
# - sensibilidade_padrao.yaml (análise de sensibilidade)
#
# =====================================================================
# VARIÁVEIS DE AMBIENTE SUPORTADAS:
# =====================================================================
# - BATCH_TIMEOUT: Timeout global (sobrepõe batch_info.timeout_global)
# - LOG_LEVEL: Nível de logging (sobrepõe logging.level)
# - OUTPUT_PATH: Caminho de saída (sobrepõe export.destination)
# - N_TRIALS: Número de trials para otimização
# - PARALLEL_JOBS: Número de jobs paralelos
# =====================================================================
# DOCUMENTAÇÃO DETALHADA - INTERNAL_JOBS
# =====================================================================
# O parâmetro internal_jobs controla o paralelismo interno dos algoritmos:
#
# 1. Localização: resources.parallel.internal_jobs
#    - Configuração global aplicada a todos os algoritmos
#    - Passado automaticamente para o algoritmo via executor_config
#
# 2. Como o Algoritmo Recebe:
#    executor_config = {
#        "internal_jobs": 4,  # Valor da configuração
#        "resources": {...}   # Configurações completas de recursos
#    }
#
# 3. Uso no Algoritmo (exemplo):
#    ```python
#    class MyAlgorithm:
#        def run(self, executor_config=None):
#            internal_jobs = executor_config.get("internal_jobs", 4)
#            
#            # Para algoritmos genéticos
#            if internal_jobs > 1:
#                # Usar paralelização na avaliação de fitness
#                with ThreadPoolExecutor(max_workers=internal_jobs) as executor:
#                    fitness_values = list(executor.map(evaluate_fitness, population))
#            
#            # Para análise de sensibilidade
#            if internal_jobs > 1:
#                # Paralelizar execuções de amostra
#                with ProcessPoolExecutor(max_workers=internal_jobs) as executor:
#                    results = list(executor.map(run_sample, samples))
#    ```
#
# 4. Considerações de Performance:
#    - max_workers: Controla quantas otimizações/análises executam simultaneamente
#    - internal_jobs: Controla paralelismo interno de cada algoritmo
#    - Fórmula: max_workers × internal_jobs ≤ CPU_cores (evitar overhead)
#
# 5. Valores Recomendados:
#    - CPU 4 cores: max_workers=1, internal_jobs=4
#    - CPU 8 cores: max_workers=2, internal_jobs=4
#    - CPU 16 cores: max_workers=4, internal_jobs=4
#    - CPU 32 cores: max_workers=8, internal_jobs=4
#
# 6. Algoritmos que se Beneficiam:
#    - BLF-GA: Paralelização da avaliação de fitness da população
#    - CSC: Paralelização da busca em blocos
#    - H³-CSP: Paralelização de candidatos
#    - Análises Morris/Sobol: Paralelização de amostras
# =====================================================================
