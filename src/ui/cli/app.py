"""
Orquestrador da Interface de Linha de Comando (CLI) para o CSP-BLFGA

Este m√≥dulo √© o cora√ß√£o da aplica√ß√£o, respons√°vel por:
- **Processar Argumentos da CLI**: Utiliza `argparse` para interpretar os comandos
  e par√¢metros fornecidos pelo usu√°rio, permitindo a execu√ß√£o em modo
  interativo ou automatizado (silencioso).
- **Gerenciar o Fluxo de Execu√ß√£o**: Orquestra as diferentes funcionalidades
  da aplica√ß√£o, como:
  - Execu√ß√£o de algoritmos individuais.
  - Execu√ß√£o em lote a partir de arquivos de configura√ß√£o YAML.
  - Otimiza√ß√£o de hiperpar√¢metros usando Optuna.
  - An√°lise de sensibilidade de par√¢metros.
- **Interagir com o Usu√°rio**:
  - Em modo interativo, utiliza os menus definidos em `src.ui.cli.menu`
    para guiar o usu√°rio na sele√ß√£o de datasets, algoritmos e configura√ß√µes.
  - Em modo silencioso, opera com base nos argumentos fornecidos, sem
    intera√ß√£o, ideal para scripts e testes automatizados.
- **Integrar com o Core do Sistema**:
  - Cria e gerencia o `SchedulerExecutor`, que executa os algoritmos de
    forma controlada e robusta.
  - Invoca a `CursesExecutionMonitor` para fornecer um monitoramento
    visual em tempo real das execu√ß√µes, se solicitado.
- **Coletar e Salvar Resultados**:
  - Utiliza `ResultsFormatter` para coletar os resultados das execu√ß√µes.
  - Gera relat√≥rios detalhados em formato de texto e CSV, salvando-os
    no diret√≥rio `outputs/reports`.
- **Configurar Logging**: Inicializa o sistema de logging para registrar
  informa√ß√µes detalhadas sobre a execu√ß√£o em `outputs/logs`.

Fluxos Principais:
1.  **Execu√ß√£o Padr√£o**: O usu√°rio seleciona um dataset, um ou mais algoritmos,
    e o n√∫mero de execu√ß√µes. A aplica√ß√£o executa os algoritmos e apresenta
    um resumo dos resultados.
2.  **Execu√ß√£o em Lote**: O usu√°rio fornece um arquivo YAML com m√∫ltiplas
    configura√ß√µes de execu√ß√£o. A aplica√ß√£o processa todas as execu√ß√µes
    definidas no arquivo.
3.  **Otimiza√ß√£o**: Um workflow guiado para otimizar os hiperpar√¢metros de um
    algoritmo em um dataset espec√≠fico.
4.  **An√°lise de Sensibilidade**: Um workflow para analisar o impacto de
    diferentes par√¢metros no desempenho de um algoritmo.
"""

"""
Arquivo principal de execu√ß√£o da aplica√ß√£o Closest String Problem (CSP).

Este m√≥dulo orquestra o fluxo principal da aplica√ß√£o, incluindo:
    1. Sele√ß√£o e leitura/gera√ß√£o do dataset.
    2. Sele√ß√£o dos algoritmos a executar.
    3. Execu√ß√£o dos algoritmos selecionados.
    4. Exibi√ß√£o e salvamento dos resultados.

A aplica√ß√£o pode ser executada em modo interativo ou automatizado (para testes).

Attributes:
    Nenhum atributo global relevante.
"""

import argparse
import logging
import os
import signal
import sys
import time
import traceback
import uuid
from datetime import datetime

from algorithms.base import global_registry
from src.core.io.results_formatter import ResultsFormatter
from src.core.report.report_utils import print_quick_summary
from src.ui.cli.console_manager import console
from src.ui.cli.menu import (
    configure_batch_optimization_params,
    configure_optimization_params,
    configure_sensitivity_params,
    menu,
    select_algorithms,
    select_dataset_for_optimization,
    select_optimization_algorithm,
    select_sensitivity_algorithm,
)
from src.ui.cli.save_wizard import ask_save_dataset
from src.utils.config import ALGORITHM_TIMEOUT, safe_input
from src.utils.logging import setup_logging

# Removed resource_monitor imports - using new scheduler system

RESULTS_DIR = "outputs/reports"
LOGS_DIR = "outputs/logs"
os.makedirs(RESULTS_DIR, exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)


def signal_handler(signum, frame):
    """Handler para sinais de interrup√ß√£o.

    Args:
        signum (int): N√∫mero do sinal recebido.
        frame (frame object): Frame atual de execu√ß√£o.
    """
    print("\n\nOpera√ß√£o cancelada pelo usu√°rio. Encerrando.")
    sys.exit(0)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Closest String Problem (CSP) - Execu√ß√£o principal"
    )
    parser.add_argument(
        "--silent",
        action="store_true",
        help="Executa em modo silencioso (sem prints interativos)",
    )
    parser.add_argument(
        "--dataset",
        type=str,
        choices=["synthetic", "file", "entrez", "batch"],
        help="Fonte do dataset",
    )
    parser.add_argument(
        "--algorithms",
        type=str,
        nargs="+",
        help="Algoritmos a executar (nomes separados por espa√ßo)",
    )
    parser.add_argument(
        "--num-execs", type=int, help="N√∫mero de execu√ß√µes por algoritmo"
    )
    parser.add_argument("--timeout", type=int, help="Timeout por execu√ß√£o (segundos)")
    parser.add_argument(
        "--workers",
        "-w",
        type=int,
        default=4,
        help="N√∫mero de workers paralelos (padr√£o: 4)",
    )
    args = parser.parse_args()

    silent = args.silent

    # Usar sempre console simples
    def silent_print(*a, **k):
        pass

    p = print if not silent else silent_print
    cprint = console.print if not silent else silent_print

    # Mostrar o n√∫mero do processo (PID) logo no in√≠cio
    p(f"[PID] Processo em execu√ß√£o: {os.getpid()}")

    # Configurar handlers de sinal para sa√≠da limpa
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        uid = uuid.uuid4().hex[:8]
        base_name = f"{ts}_{uid}"
        # Passa silent para setup_logging
        setup_logging(base_name, silent=silent)

        # Se modo silencioso, use defaults para qualquer par√¢metro n√£o informado
        if silent:
            if not args.dataset:
                args.dataset = "synthetic"
            if not args.algorithms:
                args.algorithms = [
                    "Baseline"
                ]  # Usar Baseline em vez de BLF-GA para testes
            if not args.num_execs:
                args.num_execs = 1
            if not args.timeout:
                args.timeout = ALGORITHM_TIMEOUT

        # Dataset
        params = {}
        seqs = []
        seed = None

        # Escolha do dataset
        if args.dataset:
            choice = args.dataset
            if args.dataset == "synthetic":
                from src.datasets.dataset_synthetic import generate_dataset

                seqs, p = generate_dataset(silent=silent)
                logging.debug(f"[main] Par√¢metros do dataset: {p}")
                params = {"dataset_source": "1"}
                params.update(p)
            elif args.dataset == "file":
                from src.datasets.dataset_file import load_dataset

                seqs, p = load_dataset(silent=silent)
                params = {"dataset_source": "2"}
                params.update(p)
            elif args.dataset == "entrez":
                from src.datasets.dataset_entrez import fetch_dataset

                seqs, p = fetch_dataset()
                params = {"dataset_source": "3"}
                params.update(p)
            elif args.dataset == "batch":
                from src.ui.cli.batch_executor import execute_batch_config

                # Perguntar pelo arquivo de configura√ß√£o se n√£o especificado
                if not silent:
                    config_file = safe_input(
                        "Arquivo de configura√ß√£o [batch_configs/exemplo.yaml]: "
                    ).strip()
                    if not config_file:
                        config_file = "batch_configs/exemplo.yaml"
                else:
                    config_file = "batch_configs/exemplo.yaml"

                try:
                    cprint(f"ÔøΩ Executando batch: {config_file}")

                    # Executar batch (usa curses por padr√£o se n√£o em modo silencioso)
                    use_curses = not silent
                    batch_results = execute_batch_config(
                        config_file, use_curses=use_curses, silent=silent
                    )

                    cprint(
                        f"‚úÖ Batch conclu√≠do! {len(batch_results)} execu√ß√µes processadas"
                    )
                    return

                except Exception as e:
                    cprint(f"‚ùå Erro na execu√ß√£o do batch: {e}")
                    logging.exception("Erro na execu√ß√£o do batch", exc_info=e)
                    return
            else:
                cprint("‚ùå Fonte de dataset inv√°lida.")
                return
        else:
            # Fluxo interativo
            choice = menu()
            params = {"dataset_source": choice}

            if choice == "4":
                # Execu√ß√£o em lote
                from src.ui.cli.batch_executor import execute_batch_config
                from src.ui.cli.menu import select_yaml_batch_file

                try:
                    config_file = select_yaml_batch_file()
                    if not config_file:
                        cprint(
                            "‚ùå Nenhum arquivo selecionado. Voltando ao menu principal."
                        )
                        return

                    cprint(f"üìã Executando batch: {config_file}")

                    # Executar batch com curses se n√£o em modo silencioso
                    use_curses = not silent
                    batch_results = execute_batch_config(
                        config_file, use_curses=use_curses, silent=silent
                    )

                    cprint(
                        f"‚úÖ Batch conclu√≠do! {len(batch_results)} execu√ß√µes processadas"
                    )
                    return

                except Exception as e:
                    cprint(f"‚ùå Erro na execu√ß√£o do batch: {e}")
                    logging.exception("Erro na execu√ß√£o do batch", exc_info=e)
                return
            elif choice == "5":
                # Otimiza√ß√£o de hiperpar√¢metros (interativo)
                try:
                    from src.ui.cli.menu import interactive_optimization_menu

                    interactive_optimization_menu()
                except Exception as e:
                    cprint(f"‚ùå Erro na otimiza√ß√£o: {e}")
                    logging.exception("Erro na otimiza√ß√£o", exc_info=e)
                return
            elif choice == "6":
                # An√°lise de sensibilidade
                try:
                    from src.ui.cli.menu import interactive_sensitivity_menu

                    interactive_sensitivity_menu()
                except Exception as e:
                    cprint(f"‚ùå Erro na an√°lise de sensibilidade: {e}")
                    logging.exception("Erro na an√°lise de sensibilidade", exc_info=e)
                return
            elif choice in ["1", "2", "3"]:
                try:
                    if choice == "1":
                        from src.datasets.dataset_synthetic import generate_dataset

                        seqs, p = generate_dataset(silent=silent)
                        logging.debug(f"[main] Par√¢metros do dataset: {p}")
                        params.update(p)
                        if not silent:
                            ask_save_dataset(seqs, "synthetic", p)
                    elif choice == "2":
                        from src.datasets.dataset_file import load_dataset

                        seqs, p = load_dataset(silent=silent)
                        params.update(p)
                    elif choice == "3":
                        from src.datasets.dataset_entrez import fetch_dataset

                        seqs, p = fetch_dataset()
                        params.update(p)
                        ask_save_dataset(seqs, "entrez", p)
                except Exception as exc:
                    cprint(f"Erro: {exc}")
                    logging.exception("Erro ao carregar dataset", exc_info=exc)
                    return

        # Ap√≥s carregar o dataset, extrair informa√ß√µes extras se dispon√≠veis
        seed = params.get("seed")
        logging.debug(f"[main] seed: {seed}")

        # Exibir dist√¢ncia da string base se dispon√≠vel
        distancia_base = params.get("distancia_string_base")
        if distancia_base is not None:
            cprint(f"Dist√¢ncia da string base: {distancia_base}")

        if not seqs:
            cprint("Nenhuma sequ√™ncia lida.")
            return

        alphabet = "".join(sorted(set("".join(seqs))))
        n, L = len(seqs), len(seqs[0])
        cprint(f"\nDataset: n={n}, L={L}, |Œ£|={len(alphabet)}")

        # Log simplificado do dataset
        logging.debug(f"[DATASET] n={n}, L={L}, |Œ£|={len(alphabet)}")
        if len(seqs) <= 5:
            logging.debug(f"[DATASET] Strings: {seqs}")
        else:
            logging.debug(f"[DATASET] {len(seqs)} strings (primeiras 2: {seqs[:2]})")

        # Verifica√ß√£o de recursos do sistema (simplificada)
        # TODO: Implementar verifica√ß√£o com novo sistema de monitoramento
        cprint("Sistema de recursos atualizado - verifica√ß√£o de mem√≥ria dispon√≠vel")

        # Algoritmos
        if args.algorithms:
            algs = args.algorithms
        else:
            algs = select_algorithms()
        if not algs:
            cprint("Nenhum algoritmo selecionado.")
            return

        # TODO: Implementar verifica√ß√£o de viabilidade com novo sistema
        # Por enquanto, todos os algoritmos s√£o considerados vi√°veis
        viable_algs = algs
        for alg_name in algs:
            cprint(f"‚úì {alg_name}: Algoritmo selecionado")

        if not viable_algs:
            cprint("Nenhum algoritmo selecionado.")
            return

        # N√∫mero de execu√ß√µes e timeout
        if args.num_execs:
            num_execs = args.num_execs
        else:
            runs = safe_input("\nN¬∫ execu√ß√µes p/ algoritmo [3]: ")
            num_execs = int(runs) if runs.isdigit() and int(runs) > 0 else 3
        if args.timeout:
            timeout = args.timeout
        else:
            default_timeout = ALGORITHM_TIMEOUT
            timeout_input = safe_input(
                f"\nTimeout por execu√ß√£o em segundos [{default_timeout}]: "
            )
            timeout = (
                int(timeout_input)
                if timeout_input.isdigit() and int(timeout_input) > 0
                else default_timeout
            )
        cprint(f"Timeout configurado: {timeout}s por execu√ß√£o")

        # Configurar n√∫mero de workers externos
        # Se n√£o foi fornecido via linha de comando e n√£o est√° em modo silencioso, perguntar
        if not hasattr(args, "workers_provided") and not silent:
            # Verificar se o valor foi fornecido via linha de comando
            workers_provided = "--workers" in sys.argv or "-w" in sys.argv
            if not workers_provided:
                workers_input = safe_input(f"\nN√∫mero de workers externos [4]: ")
                external_workers = (
                    int(workers_input)
                    if workers_input.isdigit() and int(workers_input) > 0
                    else 4
                )
            else:
                external_workers = args.workers
        else:
            external_workers = args.workers

        # Execu√ß√£o dos algoritmos
        cprint("\n" + "=" * 50)
        cprint("EXECUTANDO ALGORITMOS")
        cprint("=" * 50)

        # Configurar workers para execu√ß√£o
        import multiprocessing

        cpu_count = multiprocessing.cpu_count()

        # Verificar se algum algoritmo suporta paralelismo interno
        has_internal_parallel = any(
            getattr(global_registry[alg_name], "supports_internal_parallel", False)
            for alg_name in viable_algs
            if alg_name in global_registry
        )

        # Configurar workers internos baseado no n√∫mero de CPUs e workers externos
        if has_internal_parallel:
            internal_workers = max(1, cpu_count // external_workers)
        else:
            internal_workers = max(1, cpu_count // external_workers)

        # Configurar vari√°vel de ambiente para workers internos
        os.environ["INTERNAL_WORKERS"] = str(internal_workers)

        cprint("üîß Configura√ß√£o de paralelismo:")
        cprint(f"   - CPUs dispon√≠veis: {cpu_count}")
        cprint(f"   - Workers externos: {external_workers}")
        cprint(f"   - Workers internos: {internal_workers}")
        cprint(f"   - Paralelismo interno detectado: {has_internal_parallel}")

        # Perguntar sobre interface curses para monitoramento (apenas se n√£o em modo silencioso)
        use_curses_monitoring = False
        if not silent:
            curses_input = (
                safe_input("\nüñ•Ô∏è  Usar interface curses para monitoramento? (S/n): ")
                .lower()
                .strip()
            )
            use_curses_monitoring = curses_input in ["", "s", "sim", "y", "yes"]
            if use_curses_monitoring:
                cprint(
                    "üí° Usando interface curses para monitoramento - Pressione 'q' para sair"
                )
            else:
                cprint("üí° Usando modo tradicional para monitoramento")

        cprint(
            f"üöÄ Executando {len(viable_algs)} algoritmos (algoritmos determin√≠sticos: 1 execu√ß√£o, n√£o-determin√≠sticos: {num_execs} execu√ß√µes)"
        )

        if use_curses_monitoring:
            # Usar nova interface curses para execu√ß√£o
            from src.ui.curses_integration import CursesExecutionMonitor

            try:
                monitor = CursesExecutionMonitor(
                    max_workers=external_workers, timeout=timeout
                )

                # Executar algoritmos com monitoramento curses (com m√∫ltiplas execu√ß√µes)
                algorithm_results = monitor.execute_algorithms(
                    algorithm_names=viable_algs,
                    seqs=seqs,
                    alphabet=alphabet,
                    num_execs=num_execs,
                    dataset_params=params,  # Passar par√¢metros do dataset
                )

                # Converter TaskResult para formato esperado
                formatter = ResultsFormatter()
                results = {}

                for alg_name, task_results in algorithm_results.items():
                    if isinstance(task_results, list) and len(task_results) > 0:
                        # M√∫ltiplas execu√ß√µes - processar todas
                        executions = []
                        for task_result in task_results:
                            if task_result.success and task_result.distance is not None:
                                execution_result = {
                                    "tempo": task_result.time,
                                    "distancia": task_result.distance,
                                    "melhor_string": task_result.center or "",
                                    "iteracoes": task_result.metadata.get(
                                        "iteracoes", 0
                                    ),
                                    "seed": seed,
                                }
                            else:
                                execution_result = {
                                    "tempo": 0.0,
                                    "distancia": float("inf"),
                                    "melhor_string": "",
                                    "iteracoes": 0,
                                    "seed": seed,
                                }
                            executions.append(execution_result)

                        formatter.add_algorithm_results(alg_name, executions)

                        # Encontrar melhor resultado
                        valid_results = [
                            e for e in executions if e["distancia"] != float("inf")
                        ]

                        if valid_results:
                            best_exec = min(valid_results, key=lambda e: e["distancia"])
                            dist_base = params.get("distancia_string_base", "-")
                            results[alg_name] = {
                                "dist": best_exec["distancia"],
                                "dist_base": dist_base,
                                "time": best_exec["tempo"],
                            }
                        else:
                            results[alg_name] = {
                                "dist": "-",
                                "dist_base": "-",
                                "time": "-",
                                "warn": "Todas as execu√ß√µes falharam",
                            }
                    else:
                        # Resultado √∫nico ou erro
                        results[alg_name] = {
                            "dist": "-",
                            "dist_base": "-",
                            "time": "-",
                            "warn": "Erro na execu√ß√£o",
                        }

            except Exception as e:
                cprint(f"‚ùå Erro na interface curses: {e}")
                cprint("üîÑ Fallback para execu√ß√£o tradicional...")
                use_curses_monitoring = False

        if not use_curses_monitoring:
            # Execu√ß√£o tradicional usando novo sistema
            from src.core.interfaces import TaskStatus, create_executor

            formatter = ResultsFormatter()
            results = {}

            # Criar executor √∫nico para todas as execu√ß√µes
            executor = create_executor(
                timeout_seconds=timeout, max_workers=external_workers
            )

            try:
                # Executar algoritmos usando novo executor
                for alg_name in viable_algs:
                    if alg_name not in global_registry:
                        cprint(f"ERRO: Algoritmo '{alg_name}' n√£o encontrado!")
                        continue

                    AlgClass = global_registry[alg_name]

                    # Verificar se o algoritmo √© determin√≠stico
                    is_deterministic = getattr(AlgClass, "is_deterministic", False)
                    actual_num_execs = 1 if is_deterministic else num_execs

                    if is_deterministic:
                        cprint(
                            f"  üîí {alg_name} √© determin√≠stico - executando apenas 1 vez"
                        )
                    else:
                        cprint(
                            f"  üé≤ {alg_name} √© n√£o-determin√≠stico - executando {actual_num_execs} vezes"
                        )

                    logging.debug(
                        f"[ALG_EXEC] Iniciando {alg_name} com {actual_num_execs} execu√ß√µes (determin√≠stico: {is_deterministic})"
                    )

                    executions = []

                    # Submeter m√∫ltiplas execu√ß√µes baseado no tipo do algoritmo
                    for i in range(actual_num_execs):
                        if actual_num_execs == 1:
                            cprint(f"  Executando {alg_name}")
                        else:
                            cprint(
                                f"  Executando {alg_name} - Run {i+1}/{actual_num_execs}"
                            )
                        instance = AlgClass(seqs, alphabet)
                        handle = executor.submit(instance)

                        # Aguardar conclus√£o
                        while executor.poll(handle) == TaskStatus.RUNNING:
                            time.sleep(0.1)

                        result = executor.result(handle)

                        if isinstance(result, Exception):
                            execution_result = {
                                "tempo": 0.0,
                                "distancia": float("inf"),
                                "melhor_string": "",
                                "iteracoes": 0,
                                "seed": seed,
                            }
                        else:
                            # Extrair tempo do metadata se dispon√≠vel
                            metadata = result.get("metadata", {})
                            execution_time = metadata.get("execution_time", 0.0)
                            if execution_time == 0.0:
                                execution_time = metadata.get(
                                    "tempo", metadata.get("time", 0.0)
                                )

                            execution_result = {
                                "tempo": execution_time,
                                "distancia": result.get(
                                    "distance", result.get("distancia", float("inf"))
                                ),
                                "melhor_string": result.get(
                                    "center", result.get("melhor_string", "")
                                ),
                                "iteracoes": result.get("metadata", {}).get(
                                    "iteracoes", 0
                                ),
                                "seed": seed,
                            }

                        executions.append(execution_result)

                    # Processar resultados para este algoritmo
                    formatter.add_algorithm_results(alg_name, executions)

                    valid_results = [
                        e
                        for e in executions
                        if "distancia" in e and e["distancia"] != float("inf")
                    ]

                    if valid_results:
                        best_exec = min(valid_results, key=lambda e: e["distancia"])
                        dist_base = params.get("distancia_string_base", "-")
                        results[alg_name] = {
                            "dist": best_exec["distancia"],
                            "dist_base": dist_base,
                            "time": best_exec["tempo"],
                        }
                        cprint(
                            f"  ‚úÖ {alg_name}: {len(valid_results)}/{actual_num_execs} execu√ß√µes v√°lidas, melhor dist√¢ncia: {best_exec['distancia']}"
                        )
                    else:
                        results[alg_name] = {
                            "dist": "-",
                            "dist_base": "-",
                            "time": "-",
                        }
                        cprint(f"  ‚ùå {alg_name}: Todas as execu√ß√µes falharam")

            finally:
                # Garantir que o executor seja encerrado
                if hasattr(executor, "shutdown"):
                    executor.shutdown(wait=True)

        # Exibir resumo dos resultados
        print_quick_summary(results, console)

        cprint("\nüìÑ Gerando relat√≥rio detalhado...")
        # Adicionar informa√ß√µes b√°sicas ao formatter para o relat√≥rio
        if hasattr(formatter, "__dict__"):
            # Captura todas as strings base e suas dist√¢ncias
            base_strings_info = []
            for _, execs in formatter.results.items():
                for exec_data in execs:
                    if exec_data.get("melhor_string"):
                        base_strings_info.append(
                            {
                                "base_string": exec_data["melhor_string"],
                                "distancia_string_base": params.get(
                                    "distancia_string_base", "-"
                                ),
                            }
                        )
            formatter.extra_info = {
                "seed": seed,
                "params": params,
                "dataset_strings": seqs,
                "base_strings_info": base_strings_info,
            }
            logging.debug("[main] formatter configurado")

        # Usar estrutura padronizada outputs/reports com timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = os.path.join("outputs", "reports", timestamp)
        os.makedirs(results_dir, exist_ok=True)
        txt_path = os.path.join(results_dir, f"{base_name}.txt")
        csv_path = os.path.join(results_dir, f"{base_name}.csv")

        formatter.save_detailed_report(txt_path)

        # Salvar resultados detalhados em CSV
        formatter.export_to_csv(csv_path)
        cprint(f"üìÑ Resultados detalhados exportados para CSV: {csv_path}")

        # Sucesso - retornar 0 explicitamente
        if silent:
            sys.exit(0)

    except Exception as e:
        if not silent:
            console.print(f"\nERRO FATAL: {e}")
            traceback.print_exc()
        else:
            logging.exception("Erro fatal durante execu√ß√£o", exc_info=e)
        sys.exit(1)


def generate_dataset_automated():
    """Gera dataset sint√©tico com valores padr√£o para testes automatizados.

    Utiliza par√¢metros fixos para garantir reprodutibilidade em testes.

    Returns:
        tuple: Lista de strings do dataset e dicion√°rio de par√¢metros utilizados.
    """
    from src.datasets.dataset_synthetic import SYNTHETIC_DEFAULTS

    n = SYNTHETIC_DEFAULTS["n"]
    L = SYNTHETIC_DEFAULTS["L"]
    alphabet = SYNTHETIC_DEFAULTS["alphabet"]
    noise = SYNTHETIC_DEFAULTS["noise"]
    fully_random = False
    seed = 42
    params = {
        "n": n,
        "L": L,
        "alphabet": alphabet,
        "noise": noise,
        "fully_random": fully_random,
        "seed": seed,
    }
    import random

    rng = random.Random(seed)
    base_string = "".join(rng.choices(alphabet, k=L))
    data = []
    for _ in range(n):
        s = list(base_string)
        num_mut = int(round(noise * L))
        mut_pos = rng.sample(range(L), num_mut) if num_mut > 0 else []
        for pos in mut_pos:
            orig = s[pos]
            alt = rng.choice([c for c in alphabet if c != orig])
            s[pos] = alt
        new_s = "".join(s)
        data.append(new_s)
    return data, params


def run_optimization_workflow():
    """Executa o workflow de otimiza√ß√£o de hiperpar√¢metros."""
    from src.optimization.optuna_optimizer import optimize_algorithm

    console.print("\n=== Otimiza√ß√£o de Hiperpar√¢metros ===")

    # Perguntar tipo de otimiza√ß√£o
    print("\nTipo de otimiza√ß√£o:")
    print("1) Otimiza√ß√£o simples")
    print("2) Otimiza√ß√£o em lote (m√∫ltiplas configura√ß√µes)")

    opt_type = safe_input("Escolha [1]: ")

    if opt_type == "2":
        run_batch_optimization_workflow()
        return

    # Selecionar algoritmo
    algorithm_name = select_optimization_algorithm()
    if not algorithm_name:
        console.print("‚ùå Nenhum algoritmo selecionado.")
        return

    # Selecionar dataset
    seqs, alphabet, dataset_info = select_dataset_for_optimization()

    # Configurar par√¢metros
    config = configure_optimization_params()

    try:
        result = optimize_algorithm(
            algorithm_name=algorithm_name,
            sequences=seqs,
            alphabet=alphabet,
            n_trials=config["n_trials"],
            timeout_per_trial=config["timeout"],
            show_progress=True,
        )

        console.print("\n‚úÖ Otimiza√ß√£o conclu√≠da!")
        console.print(f"Melhor valor: {result.best_value}")
        console.print(f"Melhores par√¢metros: {result.best_params}")

        # Salvar visualiza√ß√µes se solicitado
        if config["save_plots"]:
            from src.optimization.visualization import OptimizationVisualizer

            visualizer = OptimizationVisualizer(result)
            plots_dir = os.path.join(RESULTS_DIR, "optimization_plots")
            os.makedirs(plots_dir, exist_ok=True)

            # Salvar gr√°ficos
            history_path = os.path.join(plots_dir, f"{algorithm_name}_history.png")
            importance_path = os.path.join(
                plots_dir, f"{algorithm_name}_importance.png"
            )

            visualizer.plot_optimization_history(save_path=history_path)
            visualizer.plot_parameter_importance(save_path=importance_path)

            console.print(f"üìä Gr√°ficos salvos em: {plots_dir}")

        # Salvar resultados
        import json

        results_path = os.path.join(
            RESULTS_DIR,
            f"optimization_{algorithm_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        )
        with open(results_path, "w") as f:
            json.dump(
                {
                    "best_params": result.best_params,
                    "best_value": result.best_value,
                    "n_trials": result.n_trials,
                    "study_name": result.study_name,
                    "optimization_time": result.optimization_time,
                    "all_trials": result.all_trials,
                },
                f,
                indent=2,
                default=str,
            )

        console.print(f"üíæ Resultados salvos em: {results_path}")

    except Exception as e:
        console.print(f"‚ùå Erro durante otimiza√ß√£o: {e}")
        logging.exception("Erro na otimiza√ß√£o", exc_info=e)


def run_batch_optimization_workflow():
    """Executa workflow de otimiza√ß√£o em lote com m√∫ltiplas configura√ß√µes."""
    import json
    import os
    from datetime import datetime

    from src.optimization.optuna_optimizer import optimize_algorithm

    console.print("\n=== Otimiza√ß√£o em Lote ===")

    # Configurar par√¢metros do batch
    batch_config = configure_batch_optimization_params()

    console.print(f"üîß Configura√ß√£o do batch:")
    console.print(f"   - Trials por configura√ß√£o: {batch_config['n_trials']}")
    console.print(f"   - Timeout por trial: {batch_config['timeout']}s")
    console.print(f"   - Configura√ß√µes de dataset: {batch_config['n_configs']}")
    console.print(f"   - Algoritmos: {', '.join(batch_config['algorithms'])}")

    # Confirmar execu√ß√£o
    confirm = safe_input("\nüöÄ Iniciar otimiza√ß√£o em lote? (S/n): ")
    if confirm.lower() in ["n", "no", "nao"]:
        console.print("‚ùå Opera√ß√£o cancelada.")
        return

    # Armazenar resultados
    batch_results = {
        "batch_info": {"timestamp": datetime.now().isoformat(), "config": batch_config},
        "results": [],
    }

    # Executar para cada configura√ß√£o de dataset
    for config_idx in range(batch_config["n_configs"]):
        console.print(f"\nüìä Configura√ß√£o {config_idx + 1}/{batch_config['n_configs']}")

        # Gerar/selecionar dataset para esta configura√ß√£o
        seqs, alphabet, dataset_info = select_dataset_for_optimization()

        config_results = {
            "config_index": config_idx + 1,
            "dataset_info": dataset_info,
            "algorithms": {},
        }

        # Executar otimiza√ß√£o para cada algoritmo
        for alg_name in batch_config["algorithms"]:
            console.print(f"\nüî¨ Otimizando {alg_name}...")

            try:
                result = optimize_algorithm(
                    algorithm_name=alg_name,
                    sequences=seqs,
                    alphabet=alphabet,
                    n_trials=batch_config["n_trials"],
                    timeout_per_trial=batch_config["timeout"],
                    show_progress=True,
                )

                config_results["algorithms"][alg_name] = {
                    "best_value": result.best_value,
                    "best_params": result.best_params,
                    "n_trials": result.n_trials,
                    "optimization_time": result.optimization_time,
                    "study_name": result.study_name,
                }

                console.print(f"‚úÖ {alg_name}: Melhor valor = {result.best_value}")

            except Exception as e:
                console.print(f"‚ùå Erro em {alg_name}: {e}")
                config_results["algorithms"][alg_name] = {
                    "error": str(e),
                    "best_value": float("inf"),
                }

        batch_results["results"].append(config_results)

    # Salvar resultados se solicitado
    if batch_config["save_results"]:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = os.path.join("outputs", "reports")
        os.makedirs(results_dir, exist_ok=True)

        results_file = os.path.join(results_dir, f"batch_optimization_{timestamp}.json")

        with open(results_file, "w") as f:
            json.dump(batch_results, f, indent=2, default=str)

        console.print(f"üíæ Resultados salvos em: {results_file}")

    # Exibir resumo
    console.print("\nüìä Resumo da Otimiza√ß√£o em Lote:")
    console.print("=" * 50)

    for result in batch_results["results"]:
        config_idx = result["config_index"]
        console.print(f"\nüìã Configura√ß√£o {config_idx}:")
        console.print(f"   Dataset: {result['dataset_info'].get('type', 'N/A')}")

        for alg_name, alg_result in result["algorithms"].items():
            if "error" in alg_result:
                console.print(f"   ‚ùå {alg_name}: {alg_result['error']}")
            else:
                console.print(f"   ‚úÖ {alg_name}: {alg_result['best_value']:.6f}")


def run_sensitivity_workflow():
    """Executa o workflow de an√°lise de sensibilidade."""
    from src.datasets.dataset_synthetic import generate_dataset
    from src.optimization.sensitivity_analyzer import analyze_algorithm_sensitivity

    console.print("\n=== An√°lise de Sensibilidade ===")

    # Selecionar algoritmo
    algorithm_name = select_sensitivity_algorithm()
    if not algorithm_name:
        console.print("‚ùå Nenhum algoritmo selecionado.")
        return

    # Configurar par√¢metros
    config = configure_sensitivity_params()

    # Gerar dataset para an√°lise
    console.print("\nüìä Gerando dataset para an√°lise...")
    seqs, _ = generate_dataset(silent=True)

    console.print(
        f"‚úÖ Dataset gerado: {len(seqs)} sequ√™ncias de tamanho {len(seqs[0])}"
    )

    # Executar an√°lise de sensibilidade
    alphabet = "".join(sorted(set("".join(seqs))))

    try:
        result = analyze_algorithm_sensitivity(
            algorithm_name=algorithm_name,
            sequences=seqs,
            alphabet=alphabet,
            n_samples=config["n_samples"],
            timeout_per_sample=config.get("timeout", 60),
            show_progress=True,
        )

        console.print("\n‚úÖ An√°lise de sensibilidade conclu√≠da!")
        console.print(f"Par√¢metros analisados: {len(result.parameter_names)}")

        # Mostrar principais par√¢metros sens√≠veis baseado no m√©todo
        console.print("\nüìà Par√¢metros mais sens√≠veis:")
        if result.method == "sobol" and result.total_order:
            # Para Sobol, usar √≠ndices de ordem total
            sorted_params = sorted(
                result.total_order.items(), key=lambda x: x[1], reverse=True
            )
            for param, value in sorted_params[:5]:
                console.print(f"  ‚Ä¢ {param}: {value:.4f}")
        elif result.method == "morris" and result.mu_star:
            # Para Morris, usar mu_star
            sorted_params = sorted(
                result.mu_star.items(), key=lambda x: x[1], reverse=True
            )
            for param, value in sorted_params[:5]:
                console.print(f"  ‚Ä¢ {param}: {value:.4f}")
        elif result.method == "fast" and result.first_order:
            # Para FAST, usar √≠ndices de primeira ordem
            sorted_params = sorted(
                result.first_order.items(), key=lambda x: x[1], reverse=True
            )
            for param, value in sorted_params[:5]:
                console.print(f"  ‚Ä¢ {param}: {value:.4f}")

        # Salvar visualiza√ß√µes se solicitado
        if config["save_plots"]:
            from src.optimization.visualization import SensitivityVisualizer

            visualizer = SensitivityVisualizer(result)
            plots_dir = os.path.join(RESULTS_DIR, "sensitivity_plots")
            os.makedirs(plots_dir, exist_ok=True)

            # Salvar gr√°ficos
            sensitivity_path = os.path.join(
                plots_dir, f"{algorithm_name}_sensitivity.png"
            )
            visualizer.plot_sensitivity_indices(save_path=sensitivity_path)

            console.print(f"üìä Gr√°ficos salvos em: {plots_dir}")

        # Salvar resultados
        import json

        results_path = os.path.join(
            RESULTS_DIR,
            f"sensitivity_{algorithm_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        )
        with open(results_path, "w") as f:
            json.dump(
                {
                    "method": result.method,
                    "parameter_names": result.parameter_names,
                    "first_order": result.first_order,
                    "total_order": result.total_order,
                    "second_order": result.second_order,
                    "mu": result.mu,
                    "mu_star": result.mu_star,
                    "sigma": result.sigma,
                    "main_effect": result.main_effect,
                    "n_samples": result.n_samples,
                    "analysis_time": result.analysis_time,
                },
                f,
                indent=2,
                default=str,
            )

        console.print(f"üíæ Resultados salvos em: {results_path}")

    except Exception as e:
        console.print(f"‚ùå Erro durante an√°lise de sensibilidade: {e}")
        logging.exception("Erro na an√°lise de sensibilidade", exc_info=e)
