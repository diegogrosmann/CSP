#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Orquestrador da Interface de Linha de Comando (CLI) para o CSP-BLFGA

Este m√≥dulo √© o cora√ß√£o da aplica√ß√£o, respons√°vel por:
- **Processar Argumentos da CLI**: Utiliza `argparse` para interpretar os comandos
  e par√¢metros fornecidos pelo usu√°rio, permitindo a execu√ß√£o em modo
  interativo ou automatizado (silencioso).
- **Gerenciar o Fluxo de Execu√ß√£o**: Orquestra as diferentes funcionalidades
  da aplica√ß√£o, como:
  - Execu√ß√£o de algoritmos individuais.
  - Execu√ß√£o em lote a partir de arquivos de configura√ß√£o YAML.
  - Otimiza√ß√£o de hiperpar√¢metros usando Optuna.
  - An√°lise de sensibilidade de par√¢metros.
- **Interagir com o Usu√°rio**:
  - Em modo interativo, utiliza os menus definidos em `src.ui.cli.menu`
    para guiar o usu√°rio na sele√ß√£o de datasets, algoritmos e configura√ß√µes.
  - Em modo silencioso, opera com base nos argumentos fornecidos, sem
    intera√ß√£o, ideal para scripts e testes automatizados.
- **Integrar com o Core do Sistema**:
  - Cria e gerencia o `SchedulerExecutor`, que executa os algoritmos de
    forma controlada e robusta.
  - Invoca a `CursesExecutionMonitor` para fornecer um monitoramento
    visual em tempo real das execu√ß√µes, se solicitado.
- **Coletar e Salvar Resultados**:
  - Utiliza `ResultsFormatter` para coletar os resultados das execu√ß√µes.
  - Gera relat√≥rios detalhados em formato de texto e CSV, salvando-os
    no diret√≥rio `outputs/reports`.
- **Configurar Logging**: Inicializa o sistema de logging para registrar
  informa√ß√µes detalhadas sobre a execu√ß√£o em `outputs/logs`.

Fluxos Principais:
1.  **Execu√ß√£o Padr√£o**: O usu√°rio seleciona um dataset, um ou mais algoritmos,
    e o n√∫mero de execu√ß√µes. A aplica√ß√£o executa os algoritmos e apresenta
    um resumo dos resultados.
2.  **Execu√ß√£o em Lote**: O usu√°rio fornece um arquivo YAML com m√∫ltiplas
    configura√ß√µes de execu√ß√£o. A aplica√ß√£o processa todas as execu√ß√µes
    definidas no arquivo.
3.  **Otimiza√ß√£o**: Um workflow guiado para otimizar os hiperpar√¢metros de um
    algoritmo em um dataset espec√≠fico.
4.  **An√°lise de Sensibilidade**: Um workflow para analisar o impacto de
    diferentes par√¢metros no desempenho de um algoritmo.
"""

import argparse
import json
import logging
import multiprocessing
import os
import random
import signal
import sys
import time
import traceback
import uuid
from datetime import datetime

# Imports do projeto
from algorithms.base import global_registry
from src.core.io.results_formatter import ResultsFormatter
from src.core.report.report_utils import print_quick_summary
from src.datasets.dataset_entrez import fetch_dataset
from src.datasets.dataset_file import load_dataset
from src.datasets.dataset_synthetic import SYNTHETIC_DEFAULTS, generate_dataset
from src.optimization.optuna_optimizer import optimize_algorithm
from src.optimization.sensitivity_analyzer import analyze_algorithm_sensitivity
from src.optimization.visualization import OptimizationVisualizer, SensitivityVisualizer
from src.ui.cli.batch_executor import execute_batch_config
from src.ui.cli.batch_processor import UnifiedBatchProcessor
from src.ui.cli.console_manager import console
from src.ui.cli.menu import (
    configure_batch_optimization_params,
    configure_optimization_params,
    configure_sensitivity_params,
    interactive_optimization_menu,
    interactive_sensitivity_menu,
    menu,
    select_algorithms,
    select_dataset_for_optimization,
    select_optimization_algorithm,
    select_sensitivity_algorithm,
    select_unified_batch_file,
)
from src.ui.cli.save_wizard import ask_save_dataset
from src.ui.curses_integration import CursesExecutionMonitor
from src.utils.config import ALGORITHM_TIMEOUT, safe_input
from src.utils.logging import setup_logging

# Configura√ß√£o de diret√≥rios
RESULTS_DIR = "outputs/reports"
LOGS_DIR = "outputs/logs"
os.makedirs(RESULTS_DIR, exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)

# Logger para o m√≥dulo principal
logger = logging.getLogger(__name__)


def signal_handler(signum, frame):
    """Handler para sinais de interrup√ß√£o.

    Args:
        signum (int): N√∫mero do sinal recebido.
        frame (frame object): Frame atual de execu√ß√£o.
    """
    print("\n\nOpera√ß√£o cancelada pelo usu√°rio. Encerrando.")
    sys.exit(0)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Closest String Problem (CSP) - Execu√ß√£o principal"
    )
    parser.add_argument(
        "--silent",
        action="store_true",
        help="Executa em modo silencioso (sem prints interativos)",
    )
    parser.add_argument(
        "--batch", type=str, help="Arquivo de configura√ß√£o batch unificado (YAML)"
    )
    parser.add_argument(
        "--dataset",
        type=str,
        choices=["synthetic", "file", "entrez"],
        help="Fonte do dataset",
    )
    parser.add_argument(
        "--algorithms",
        type=str,
        nargs="+",
        help="Algoritmos a executar (nomes separados por espa√ßo)",
    )
    parser.add_argument(
        "--num-execs", type=int, help="N√∫mero de execu√ß√µes por algoritmo"
    )
    parser.add_argument("--timeout", type=int, help="Timeout por execu√ß√£o (segundos)")
    parser.add_argument(
        "--workers",
        "-w",
        type=int,
        default=4,
        help="N√∫mero de workers paralelos (padr√£o: 4)",
    )
    args = parser.parse_args()

    silent = args.silent

    # Usar sempre console simples
    def silent_print(*a, **k):
        pass

    p = print if not silent else silent_print
    cprint = console.print if not silent else silent_print

    # Mostrar o n√∫mero do processo (PID) logo no in√≠cio
    p(f"[PID] Processo em execu√ß√£o: {os.getpid()}")

    # Configurar handlers de sinal para sa√≠da limpa
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        uid = uuid.uuid4().hex[:8]
        base_name = f"{ts}_{uid}"
        # Configurar logging inicial sem console para batch
        setup_logging(base_name, silent=silent, console=False)

        # Verificar se foi fornecido arquivo de batch
        if args.batch:
            # Processar batch unificado
            try:
                if not os.path.exists(args.batch):
                    cprint(f"‚ùå Arquivo de configura√ß√£o n√£o encontrado: {args.batch}")
                    return

                # Primeiro, extrair configura√ß√£o de log do batch para reconfigurar logging
                try:
                    from src.ui.cli.batch_config_extractor import BatchConfigExtractor

                    batch_extractor = BatchConfigExtractor(args.batch)
                    batch_log_level = batch_extractor.get_log_level()

                    # Reconfigurar logging com o n√≠vel espec√≠fico do batch
                    setup_logging(
                        base_name, silent=silent, level=batch_log_level, console=False
                    )
                    logger.info(f"Logging reconfigurado com n√≠vel: {batch_log_level}")

                except Exception as e:
                    logger.warning(
                        f"Erro ao configurar logging do batch, usando padr√£o: {e}"
                    )

                cprint(f"üöÄ Processando batch unificado: {args.batch}")

                processor = UnifiedBatchProcessor(args.batch, silent=silent)
                results = processor.process()

                cprint("‚úÖ Batch conclu√≠do! Resultados processados com sucesso.")

                # Salvar resultados se necess√°rio
                if not silent:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    results_dir = os.path.join(
                        "outputs", "reports", f"batch_{timestamp}"
                    )
                    os.makedirs(results_dir, exist_ok=True)

                    results_file = os.path.join(results_dir, "batch_results.json")
                    with open(results_file, "w", encoding="utf-8") as f:
                        json.dump(results, f, indent=2, default=str)

                    cprint(f"üìÅ Resultados salvos em: {results_file}")

                return

            except (OSError, IOError, ValueError) as e:
                cprint(f"‚ùå Erro no processamento do batch: {e}")
                logging.exception("Erro no processamento do batch", exc_info=e)
                return

        # Se modo silencioso, use defaults para qualquer par√¢metro n√£o informado
        if silent:
            if not args.dataset:
                args.dataset = "synthetic"
            if not args.algorithms:
                args.algorithms = [
                    "Baseline"
                ]  # Usar Baseline em vez de BLF-GA para testes
            if not args.num_execs:
                args.num_execs = 1
            if not args.timeout:
                args.timeout = ALGORITHM_TIMEOUT

        # Dataset
        params = {}
        seqs = []
        seed = None

        # Escolha do dataset
        if args.dataset:
            choice = args.dataset
            if args.dataset == "synthetic":
                seqs, p = generate_dataset(silent=silent)
                logging.debug("[main] Par√¢metros do dataset: %s", p)
                params = {"dataset_source": "1"}
                params.update(p)
            elif args.dataset == "file":
                seqs, p = load_dataset(silent=silent)
                params = {"dataset_source": "2"}
                params.update(p)
            elif args.dataset == "entrez":
                seqs, p = fetch_dataset()
                params = {"dataset_source": "3"}
                params.update(p)
            elif args.dataset == "batch":
                # Perguntar pelo arquivo de configura√ß√£o se n√£o especificado
                if not silent:
                    config_file = safe_input(
                        "Arquivo de configura√ß√£o [batch_configs/exemplo.yaml]: "
                    ).strip()
                    if not config_file:
                        config_file = "batch_configs/exemplo.yaml"
                else:
                    config_file = "batch_configs/exemplo.yaml"

                try:
                    cprint(f"üöÄ Executando batch: {config_file}")

                    # Executar batch (usa curses por padr√£o se n√£o em modo silencioso)
                    use_curses = not silent
                    batch_results = execute_batch_config(
                        config_file, use_curses=use_curses, silent=silent
                    )

                    cprint(
                        f"‚úÖ Batch conclu√≠do! {len(batch_results)} execu√ß√µes processadas"
                    )
                    return

                except (OSError, IOError, ValueError) as e:
                    cprint(f"‚ùå Erro na execu√ß√£o do batch: {e}")
                    logging.exception("Erro na execu√ß√£o do batch", exc_info=e)
                    return
            else:
                cprint("‚ùå Fonte de dataset inv√°lida.")
                return
        else:
            # Fluxo interativo
            choice = menu()
            params = {"dataset_source": choice}

            if choice == "4":
                # Execu√ß√£o em lote unificada
                try:
                    config_file = select_unified_batch_file()
                    if not config_file:
                        cprint(
                            "‚ùå Nenhum arquivo selecionado. Voltando ao menu principal."
                        )
                        return

                    cprint(f"ÔøΩ Processando batch unificado: {config_file}")

                    processor = UnifiedBatchProcessor(config_file, silent=silent)
                    results = processor.process()

                    cprint("‚úÖ Batch conclu√≠do! Resultados processados com sucesso.")

                    # Salvar resultados
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    results_dir = os.path.join(
                        "outputs", "reports", f"batch_{timestamp}"
                    )
                    os.makedirs(results_dir, exist_ok=True)

                    results_file = os.path.join(results_dir, "batch_results.json")
                    with open(results_file, "w", encoding="utf-8") as f:
                        json.dump(results, f, indent=2, default=str)

                    cprint(f"üìÅ Resultados salvos em: {results_file}")
                    return

                except (OSError, IOError, ValueError) as e:
                    cprint(f"‚ùå Erro no processamento do batch: {e}")
                    logging.exception("Erro no processamento do batch", exc_info=e)
                return
            elif choice == "5":
                # Otimiza√ß√£o de hiperpar√¢metros (interativo)
                try:
                    interactive_optimization_menu()
                except (ImportError, AttributeError, ValueError) as e:
                    cprint(f"‚ùå Erro na otimiza√ß√£o: {e}")
                    logging.exception("Erro na otimiza√ß√£o", exc_info=e)
                return
            elif choice == "6":
                # An√°lise de sensibilidade
                try:
                    interactive_sensitivity_menu()
                except (ImportError, AttributeError, ValueError) as e:
                    cprint(f"‚ùå Erro na an√°lise de sensibilidade: {e}")
                    logging.exception("Erro na an√°lise de sensibilidade", exc_info=e)
                return
            elif choice in ["1", "2", "3"]:
                try:
                    if choice == "1":
                        seqs, p = generate_dataset(silent=silent)
                        logging.debug("[main] Par√¢metros do dataset: %s", p)
                        params.update(p)
                        if not silent:
                            ask_save_dataset(seqs, "synthetic", p)
                    elif choice == "2":
                        seqs, p = load_dataset(silent=silent)
                        params.update(p)
                    elif choice == "3":
                        seqs, p = fetch_dataset()
                        params.update(p)
                        ask_save_dataset(seqs, "entrez", p)
                except (OSError, IOError, ValueError) as exc:
                    cprint(f"Erro: {exc}")
                    logging.exception("Erro ao carregar dataset", exc_info=exc)
                    return

        # Ap√≥s carregar o dataset, extrair informa√ß√µes extras se dispon√≠veis
        seed = params.get("seed")
        logging.debug("[main] seed: %s", seed)

        # Exibir dist√¢ncia da string base se dispon√≠vel
        distancia_base = params.get("distancia_string_base")
        if distancia_base is not None:
            cprint(f"Dist√¢ncia da string base: {distancia_base}")

        if not seqs:
            cprint("Nenhuma sequ√™ncia lida.")
            return

        alphabet = "".join(sorted(set("".join(seqs))))
        n, L = len(seqs), len(seqs[0])
        cprint(f"\nDataset: n={n}, L={L}, |Œ£|={len(alphabet)}")

        # Log simplificado do dataset
        logging.debug("[DATASET] n=%s, L=%s, |Œ£|=%s", n, L, len(alphabet))
        if len(seqs) <= 5:
            logging.debug("[DATASET] Strings: %s", seqs)
        else:
            logging.debug("[DATASET] %s strings (primeiras 2: %s)", len(seqs), seqs[:2])

        # Verifica√ß√£o de recursos do sistema (simplificada)
        # TODO: Implementar verifica√ß√£o com novo sistema de monitoramento
        cprint("Sistema de recursos atualizado - verifica√ß√£o de mem√≥ria dispon√≠vel")

        # Algoritmos
        if args.algorithms:
            algs = args.algorithms
        else:
            algs = select_algorithms()
        if not algs:
            cprint("Nenhum algoritmo selecionado.")
            return

        # TODO: Implementar verifica√ß√£o de viabilidade com novo sistema
        # Por enquanto, todos os algoritmos s√£o considerados vi√°veis
        viable_algs = algs
        for alg_name in algs:
            cprint(f"‚úì {alg_name}: Algoritmo selecionado")

        if not viable_algs:
            cprint("Nenhum algoritmo selecionado.")
            return

        # N√∫mero de execu√ß√µes e timeout
        if args.num_execs:
            num_execs = args.num_execs
        else:
            runs = safe_input("\nN¬∫ execu√ß√µes p/ algoritmo [3]: ")
            num_execs = int(runs) if runs.isdigit() and int(runs) > 0 else 3
        if args.timeout:
            timeout = args.timeout
        else:
            default_timeout = ALGORITHM_TIMEOUT
            timeout_input = safe_input(
                f"\nTimeout por execu√ß√£o em segundos [{default_timeout}]: "
            )
            timeout = (
                int(timeout_input)
                if timeout_input.isdigit() and int(timeout_input) > 0
                else default_timeout
            )
        cprint(f"Timeout configurado: {timeout}s por execu√ß√£o")

        # Configurar n√∫mero de workers externos
        # Se n√£o foi fornecido via linha de comando e n√£o est√° em modo silencioso, perguntar
        if not hasattr(args, "workers_provided") and not silent:
            # Verificar se o valor foi fornecido via linha de comando
            workers_provided = "--workers" in sys.argv or "-w" in sys.argv
            if not workers_provided:
                workers_input = safe_input("\nN√∫mero de workers externos [4]: ")
                external_workers = (
                    int(workers_input)
                    if workers_input.isdigit() and int(workers_input) > 0
                    else 4
                )
            else:
                external_workers = args.workers
        else:
            external_workers = args.workers

        # Execu√ß√£o dos algoritmos
        cprint("\n" + "=" * 50)
        cprint("EXECUTANDO ALGORITMOS")
        cprint("=" * 50)

        # Configurar workers para execu√ß√£o
        cpu_count = multiprocessing.cpu_count()

        # Verificar se algum algoritmo suporta paralelismo interno
        has_internal_parallel = any(
            getattr(global_registry[alg_name], "supports_internal_parallel", False)
            for alg_name in viable_algs
            if alg_name in global_registry
        )

        # Configurar workers internos baseado no n√∫mero de CPUs e workers externos
        if has_internal_parallel:
            internal_workers = max(1, cpu_count // external_workers)
        else:
            internal_workers = max(1, cpu_count // external_workers)

        # Configurar vari√°vel de ambiente para workers internos
        os.environ["INTERNAL_WORKERS"] = str(internal_workers)

        cprint("üîß Configura√ß√£o de paralelismo:")
        cprint(f"   - CPUs dispon√≠veis: {cpu_count}")
        cprint(f"   - Workers externos: {external_workers}")
        cprint(f"   - Workers internos: {internal_workers}")
        cprint(f"   - Paralelismo interno detectado: {has_internal_parallel}")

        # Perguntar sobre interface curses para monitoramento (apenas se n√£o em modo silencioso)
        use_curses_monitoring = False
        if not silent:
            curses_input = (
                safe_input("\nüñ•Ô∏è  Usar interface curses para monitoramento? (S/n): ")
                .lower()
                .strip()
            )
            use_curses_monitoring = curses_input in ["", "s", "sim", "y", "yes"]
            if use_curses_monitoring:
                cprint(
                    "üí° Usando interface curses para monitoramento - Pressione 'q' para sair"
                )
            else:
                cprint("üí° Usando modo tradicional para monitoramento")

        cprint(
            f"üöÄ Executando {len(viable_algs)} algoritmos (algoritmos determin√≠sticos: 1 execu√ß√£o, n√£o-determin√≠sticos: {num_execs} execu√ß√µes)"
        )

        if use_curses_monitoring:
            # Usar nova interface curses para execu√ß√£o
            try:
                monitor = CursesExecutionMonitor(
                    max_workers=external_workers, timeout=timeout
                )

                # Executar algoritmos com monitoramento curses (com m√∫ltiplas execu√ß√µes)
                algorithm_results = monitor.execute_algorithms(
                    algorithm_names=viable_algs,
                    seqs=seqs,
                    alphabet=alphabet,
                    num_execs=num_execs,
                    dataset_params=params,  # Passar par√¢metros do dataset
                )

                # Converter TaskResult para formato esperado
                formatter = ResultsFormatter()
                results = {}

                for alg_name, task_results in algorithm_results.items():
                    if isinstance(task_results, list) and len(task_results) > 0:
                        # M√∫ltiplas execu√ß√µes - processar todas
                        executions = []
                        for task_result in task_results:
                            if task_result.success and task_result.distance is not None:
                                execution_result = {
                                    "tempo": task_result.time,
                                    "distancia": task_result.distance,
                                    "melhor_string": task_result.center or "",
                                    "iteracoes": task_result.metadata.get(
                                        "iteracoes", 0
                                    ),
                                    "seed": seed,
                                }
                            else:
                                execution_result = {
                                    "tempo": 0.0,
                                    "distancia": float("inf"),
                                    "melhor_string": "",
                                    "iteracoes": 0,
                                    "seed": seed,
                                }
                            executions.append(execution_result)

                        formatter.add_algorithm_results(alg_name, executions)

                        # Encontrar melhor resultado
                        valid_results = [
                            e for e in executions if e["distancia"] != float("inf")
                        ]

                        if valid_results:
                            best_exec = min(valid_results, key=lambda e: e["distancia"])
                            dist_base = params.get("distancia_string_base", "-")
                            results[alg_name] = {
                                "dist": best_exec["distancia"],
                                "dist_base": dist_base,
                                "time": best_exec["tempo"],
                            }
                        else:
                            results[alg_name] = {
                                "dist": "-",
                                "dist_base": "-",
                                "time": "-",
                                "warn": "Todas as execu√ß√µes falharam",
                            }
                    else:
                        # Resultado √∫nico ou erro
                        results[alg_name] = {
                            "dist": "-",
                            "dist_base": "-",
                            "time": "-",
                            "warn": "Erro na execu√ß√£o",
                        }

            except Exception as e:
                cprint(f"‚ùå Erro na interface curses: {e}")
                cprint("üîÑ Fallback para execu√ß√£o tradicional...")
                use_curses_monitoring = False

        if not use_curses_monitoring:
            # Execu√ß√£o tradicional simplificada
            formatter = ResultsFormatter()
            results = {}

            # Executar algoritmos diretamente
            for alg_name in viable_algs:
                if alg_name not in global_registry:
                    cprint(f"ERRO: Algoritmo '{alg_name}' n√£o encontrado!")
                    continue

                AlgClass = global_registry[alg_name]

                # Verificar se o algoritmo √© determin√≠stico
                is_deterministic = getattr(AlgClass, "is_deterministic", False)
                actual_num_execs = 1 if is_deterministic else num_execs

                if is_deterministic:
                    cprint(
                        f"  üîí {alg_name} √© determin√≠stico - executando apenas 1 vez"
                    )
                else:
                    cprint(
                        f"  üé≤ {alg_name} √© n√£o-determin√≠stico - executando {actual_num_execs} vezes"
                    )

                logging.debug(
                    "[ALG_EXEC] Iniciando %s com %s execu√ß√µes (determin√≠stico: %s)",
                    alg_name,
                    actual_num_execs,
                    is_deterministic,
                )

                executions = []

                # Executar cada algoritmo m√∫ltiplas vezes
                for i in range(actual_num_execs):
                    if actual_num_execs == 1:
                        cprint(f"  Executando {alg_name}")
                    else:
                        cprint(
                            f"  Executando {alg_name} - Run {i+1}/{actual_num_execs}"
                        )

                    try:
                        # Criar inst√¢ncia do algoritmo
                        instance = AlgClass(seqs, alphabet)

                        # Executar algoritmo diretamente com timeout
                        start_time = time.time()
                        result = instance.run()
                        end_time = time.time()
                        execution_time = end_time - start_time

                        # Verificar se ultrapassou timeout
                        if execution_time > timeout:
                            cprint(
                                f"    ‚è∞ Timeout de {timeout}s excedido ({execution_time:.2f}s)"
                            )
                            execution_result = {
                                "tempo": timeout,
                                "distancia": float("inf"),
                                "melhor_string": "",
                                "iteracoes": 0,
                                "seed": seed,
                            }
                        else:
                            # Processar resultado (tuple: center, distance, metadata)
                            if isinstance(result, tuple) and len(result) >= 2:
                                center, distance = result[0], result[1]
                                metadata = result[2] if len(result) > 2 else {}
                            elif isinstance(result, dict):
                                distance = result.get(
                                    "distance", result.get("distancia", float("inf"))
                                )
                                center = result.get(
                                    "center", result.get("melhor_string", "")
                                )
                                metadata = result
                            else:
                                # Tentar acessar como atributos (fallback)
                                try:
                                    distance = getattr(result, "distance", float("inf"))
                                    center = getattr(result, "center", "")
                                    metadata = {}
                                except AttributeError:
                                    distance = float("inf")
                                    center = ""
                                    metadata = {}

                            execution_result = {
                                "tempo": execution_time,
                                "distancia": distance,
                                "melhor_string": center,
                                "iteracoes": metadata.get(
                                    "iteracoes", metadata.get("generations_executed", 0)
                                ),
                                "seed": seed,
                                "metadata": metadata,
                            }

                            cprint(
                                f"    ‚úÖ Conclu√≠do em {execution_time:.2f}s - Dist√¢ncia: {distance}"
                            )

                    except Exception as e:
                        cprint(f"    ‚ùå Erro na execu√ß√£o: {e}")
                        execution_result = {
                            "tempo": 0.0,
                            "distancia": float("inf"),
                            "melhor_string": "",
                            "iteracoes": 0,
                            "seed": seed,
                        }

                    executions.append(execution_result)

                # Processar resultados para este algoritmo
                formatter.add_algorithm_results(alg_name, executions)

                valid_results = [
                    e
                    for e in executions
                    if "distancia" in e and e["distancia"] != float("inf")
                ]

                if valid_results:
                    best_exec = min(valid_results, key=lambda e: e["distancia"])
                    dist_base = params.get("distancia_string_base", "-")
                    results[alg_name] = {
                        "dist": best_exec["distancia"],
                        "dist_base": dist_base,
                        "time": best_exec["tempo"],
                    }
                    cprint(
                        f"  ‚úÖ {alg_name}: {len(valid_results)}/{actual_num_execs} execu√ß√µes v√°lidas, melhor dist√¢ncia: {best_exec['distancia']}"
                    )
                else:
                    results[alg_name] = {
                        "dist": "-",
                        "dist_base": "-",
                        "time": "-",
                    }
                    cprint(f"  ‚ùå {alg_name}: Todas as execu√ß√µes falharam")

        # Exibir resumo dos resultados
        print_quick_summary(results, console)

        cprint("\nüìÑ Gerando relat√≥rio detalhado...")
        # Adicionar informa√ß√µes b√°sicas ao formatter para o relat√≥rio
        if hasattr(formatter, "__dict__"):
            # Captura todas as strings base e suas dist√¢ncias
            base_strings_info = []
            for _, execs in formatter.results.items():
                for exec_data in execs:
                    if exec_data.get("melhor_string"):
                        base_strings_info.append(
                            {
                                "base_string": exec_data["melhor_string"],
                                "distancia_string_base": params.get(
                                    "distancia_string_base", "-"
                                ),
                            }
                        )
            formatter.extra_info = {
                "seed": seed,
                "params": params,
                "dataset_strings": seqs,
                "base_strings_info": base_strings_info,
            }
            logging.debug("[main] formatter configurado")

        # Usar estrutura padronizada outputs/reports com timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = os.path.join("outputs", "reports", timestamp)
        os.makedirs(results_dir, exist_ok=True)
        txt_path = os.path.join(results_dir, f"{base_name}.txt")
        csv_path = os.path.join(results_dir, f"{base_name}.csv")

        formatter.save_detailed_report(txt_path)

        # Salvar resultados detalhados em CSV
        formatter.export_to_csv(csv_path)
        cprint(f"üìÑ Resultados detalhados exportados para CSV: {csv_path}")

        # Sucesso - retornar 0 explicitamente
        if silent:
            sys.exit(0)

    except Exception as e:
        if not silent:
            console.print(f"\nERRO FATAL: {e}")
            traceback.print_exc()
        else:
            logging.exception("Erro fatal durante execu√ß√£o", exc_info=e)
        sys.exit(1)


def generate_dataset_automated():
    """Gera dataset sint√©tico com valores padr√£o para testes automatizados.

    Utiliza par√¢metros fixos para garantir reprodutibilidade em testes.

    Returns:
        tuple: Lista de strings do dataset e dicion√°rio de par√¢metros utilizados.
    """
    n = SYNTHETIC_DEFAULTS["n"]
    L = SYNTHETIC_DEFAULTS["L"]
    alphabet = SYNTHETIC_DEFAULTS["alphabet"]
    noise = SYNTHETIC_DEFAULTS["noise"]
    fully_random = False
    seed = 42
    params = {
        "n": n,
        "L": L,
        "alphabet": alphabet,
        "noise": noise,
        "fully_random": fully_random,
        "seed": seed,
    }
    rng = random.Random(seed)
    base_string = "".join(rng.choices(alphabet, k=L))
    data = []
    for _ in range(n):
        s = list(base_string)
        num_mut = int(round(noise * L))
        mut_pos = rng.sample(range(L), num_mut) if num_mut > 0 else []
        for pos in mut_pos:
            orig = s[pos]
            alt = rng.choice([c for c in alphabet if c != orig])
            s[pos] = alt
        new_s = "".join(s)
        data.append(new_s)
    return data, params


def run_optimization_workflow():
    """Executa o workflow de otimiza√ß√£o de hiperpar√¢metros."""
    console.print("\n=== Otimiza√ß√£o de Hiperpar√¢metros ===")

    # Perguntar tipo de otimiza√ß√£o
    print("\nTipo de otimiza√ß√£o:")
    print("1) Otimiza√ß√£o simples")
    print("2) Otimiza√ß√£o em lote (m√∫ltiplas configura√ß√µes)")

    opt_type = safe_input("Escolha [1]: ")

    if opt_type == "2":
        run_batch_optimization_workflow()
        return

    # Selecionar algoritmo
    algorithm_name = select_optimization_algorithm()
    if not algorithm_name:
        console.print("‚ùå Nenhum algoritmo selecionado.")
        return

    # Selecionar dataset
    seqs, alphabet, dataset_info = select_dataset_for_optimization()

    # Configurar par√¢metros
    config = configure_optimization_params()

    try:
        result = optimize_algorithm(
            algorithm_name=algorithm_name,
            sequences=seqs,
            alphabet=alphabet,
            n_trials=config["n_trials"],
            timeout_per_trial=config["timeout"],
            show_progress=True,
        )

        console.print("\n‚úÖ Otimiza√ß√£o conclu√≠da!")
        console.print(f"Melhor valor: {result.best_value}")
        console.print(f"Melhores par√¢metros: {result.best_params}")

        # Salvar visualiza√ß√µes se solicitado
        if config["save_plots"]:
            visualizer = OptimizationVisualizer(result)
            plots_dir = os.path.join(RESULTS_DIR, "optimization_plots")
            os.makedirs(plots_dir, exist_ok=True)

            # Salvar gr√°ficos
            history_path = os.path.join(plots_dir, f"{algorithm_name}_history.png")
            importance_path = os.path.join(
                plots_dir, f"{algorithm_name}_importance.png"
            )

            visualizer.plot_optimization_history(save_path=history_path)
            visualizer.plot_parameter_importance(save_path=importance_path)

            console.print(f"üìä Gr√°ficos salvos em: {plots_dir}")

        # Salvar resultados
        results_path = os.path.join(
            RESULTS_DIR,
            f"optimization_{algorithm_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        )
        with open(results_path, "w", encoding="utf-8") as f:
            json.dump(
                {
                    "best_params": result.best_params,
                    "best_value": result.best_value,
                    "n_trials": result.n_trials,
                    "study_name": result.study_name,
                    "optimization_time": result.optimization_time,
                    "all_trials": result.all_trials,
                },
                f,
                indent=2,
                default=str,
            )

        console.print(f"üíæ Resultados salvos em: {results_path}")

    except Exception as e:
        console.print(f"‚ùå Erro durante otimiza√ß√£o: {e}")
        logging.exception("Erro na otimiza√ß√£o", exc_info=e)


def run_batch_optimization_workflow():
    """Executa workflow de otimiza√ß√£o em lote com m√∫ltiplas configura√ß√µes."""
    console.print("\n=== Otimiza√ß√£o em Lote ===")

    # Configurar par√¢metros do batch
    batch_config = configure_batch_optimization_params()

    console.print("üîß Configura√ß√£o do batch:")
    console.print(f"   - Trials por configura√ß√£o: {batch_config['n_trials']}")
    console.print(f"   - Timeout por trial: {batch_config['timeout']}s")
    console.print(f"   - Configura√ß√µes de dataset: {batch_config['n_configs']}")
    console.print(f"   - Algoritmos: {', '.join(batch_config['algorithms'])}")

    # Confirmar execu√ß√£o
    confirm = safe_input("\nüöÄ Iniciar otimiza√ß√£o em lote? (S/n): ")
    if confirm.lower() in ["n", "no", "nao"]:
        console.print("‚ùå Opera√ß√£o cancelada.")
        return

    # Armazenar resultados
    batch_results = {
        "batch_info": {"timestamp": datetime.now().isoformat(), "config": batch_config},
        "results": [],
    }

    # Executar para cada configura√ß√£o de dataset
    for config_idx in range(batch_config["n_configs"]):
        console.print(f"\nüìä Configura√ß√£o {config_idx + 1}/{batch_config['n_configs']}")

        # Gerar/selecionar dataset para esta configura√ß√£o
        seqs, alphabet, dataset_info = select_dataset_for_optimization()

        config_results = {
            "config_index": config_idx + 1,
            "dataset_info": dataset_info,
            "algorithms": {},
        }

        # Executar otimiza√ß√£o para cada algoritmo
        for alg_name in batch_config["algorithms"]:
            console.print(f"\nüî¨ Otimizando {alg_name}...")

            try:
                result = optimize_algorithm(
                    algorithm_name=alg_name,
                    sequences=seqs,
                    alphabet=alphabet,
                    n_trials=batch_config["n_trials"],
                    timeout_per_trial=batch_config["timeout"],
                    show_progress=True,
                )

                config_results["algorithms"][alg_name] = {
                    "best_value": result.best_value,
                    "best_params": result.best_params,
                    "n_trials": result.n_trials,
                    "optimization_time": result.optimization_time,
                    "study_name": result.study_name,
                }

                console.print(f"‚úÖ {alg_name}: Melhor valor = {result.best_value}")

            except Exception as e:
                console.print(f"‚ùå Erro em {alg_name}: {e}")
                config_results["algorithms"][alg_name] = {
                    "error": str(e),
                    "best_value": float("inf"),
                }

        batch_results["results"].append(config_results)

    # Salvar resultados se solicitado
    if batch_config["save_results"]:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = os.path.join("outputs", "reports")
        os.makedirs(results_dir, exist_ok=True)

        results_file = os.path.join(results_dir, f"batch_optimization_{timestamp}.json")

        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(batch_results, f, indent=2, default=str)

        console.print(f"üíæ Resultados salvos em: {results_file}")

    # Exibir resumo
    console.print("\nüìä Resumo da Otimiza√ß√£o em Lote:")
    console.print("=" * 50)

    for result in batch_results["results"]:
        config_idx = result["config_index"]
        console.print(f"\nüìã Configura√ß√£o {config_idx}:")
        console.print(f"   Dataset: {result['dataset_info'].get('type', 'N/A')}")

        for alg_name, alg_result in result["algorithms"].items():
            if "error" in alg_result:
                console.print(f"   ‚ùå {alg_name}: {alg_result['error']}")
            else:
                console.print(f"   ‚úÖ {alg_name}: {alg_result['best_value']:.6f}")


def run_sensitivity_workflow():
    """Executa o workflow de an√°lise de sensibilidade."""
    console.print("\n=== An√°lise de Sensibilidade ===")

    # Selecionar algoritmo
    algorithm_name = select_sensitivity_algorithm()
    if not algorithm_name:
        console.print("‚ùå Nenhum algoritmo selecionado.")
        return

    # Configurar par√¢metros
    config = configure_sensitivity_params()

    # Gerar dataset para an√°lise
    console.print("\nüìä Gerando dataset para an√°lise...")
    seqs, _ = generate_dataset(silent=True)

    console.print(
        f"‚úÖ Dataset gerado: {len(seqs)} sequ√™ncias de tamanho {len(seqs[0])}"
    )

    # Executar an√°lise de sensibilidade
    alphabet = "".join(sorted(set("".join(seqs))))

    try:
        result = analyze_algorithm_sensitivity(
            algorithm_name=algorithm_name,
            sequences=seqs,
            alphabet=alphabet,
            n_samples=config["n_samples"],
            timeout_per_sample=config.get("timeout", 60),
            show_progress=True,
        )

        console.print("\n‚úÖ An√°lise de sensibilidade conclu√≠da!")
        console.print(f"Par√¢metros analisados: {len(result.parameter_names)}")

        # Mostrar principais par√¢metros sens√≠veis baseado no m√©todo
        console.print("\nüìà Par√¢metros mais sens√≠veis:")
        if result.method == "sobol" and result.total_order:
            # Para Sobol, usar √≠ndices de ordem total
            sorted_params = sorted(
                result.total_order.items(), key=lambda x: x[1], reverse=True
            )
            for param, value in sorted_params[:5]:
                console.print(f"  ‚Ä¢ {param}: {value:.4f}")
        elif result.method == "morris" and result.mu_star:
            # Para Morris, usar mu_star
            sorted_params = sorted(
                result.mu_star.items(), key=lambda x: x[1], reverse=True
            )
            for param, value in sorted_params[:5]:
                console.print(f"  ‚Ä¢ {param}: {value:.4f}")
        elif result.method == "fast" and result.first_order:
            # Para FAST, usar √≠ndices de primeira ordem
            sorted_params = sorted(
                result.first_order.items(), key=lambda x: x[1], reverse=True
            )
            for param, value in sorted_params[:5]:
                console.print(f"  ‚Ä¢ {param}: {value:.4f}")

        # Salvar visualiza√ß√µes se solicitado
        if config["save_plots"]:
            visualizer = SensitivityVisualizer(result)
            plots_dir = os.path.join(RESULTS_DIR, "sensitivity_plots")
            os.makedirs(plots_dir, exist_ok=True)

            # Salvar gr√°ficos
            sensitivity_path = os.path.join(
                plots_dir, f"{algorithm_name}_sensitivity.png"
            )
            visualizer.plot_sensitivity_indices(save_path=sensitivity_path)

            console.print(f"üìä Gr√°ficos salvos em: {plots_dir}")

        # Salvar resultados
        results_path = os.path.join(
            RESULTS_DIR,
            f"sensitivity_{algorithm_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        )
        with open(results_path, "w", encoding="utf-8") as f:
            json.dump(
                {
                    "method": result.method,
                    "parameter_names": result.parameter_names,
                    "first_order": result.first_order,
                    "total_order": result.total_order,
                    "second_order": result.second_order,
                    "mu": result.mu,
                    "mu_star": result.mu_star,
                    "sigma": result.sigma,
                    "main_effect": result.main_effect,
                    "n_samples": result.n_samples,
                    "analysis_time": result.analysis_time,
                },
                f,
                indent=2,
                default=str,
            )

        console.print(f"üíæ Resultados salvos em: {results_path}")

    except Exception as e:
        console.print(f"‚ùå Erro durante an√°lise de sensibilidade: {e}")
        logging.exception("Erro na an√°lise de sensibilidade", exc_info=e)
